{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13972175,"sourceType":"datasetVersion","datasetId":8832408}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q openai-whisper\n!pip install -q transformers sentencepiece accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:28:16.193447Z","iopub.execute_input":"2025-12-12T09:28:16.193778Z","iopub.status.idle":"2025-12-12T09:29:36.167612Z","shell.execute_reply.started":"2025-12-12T09:28:16.193753Z","shell.execute_reply":"2025-12-12T09:29:36.166811Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"## whisper large: flan t5-large: comprehensive : best qlty\n\n\"\"\"\nSmart T5 Abstractive Audio Summarizer\nHandles ANY audio length (30 seconds to 3+ hours)\nUses Google's T5 model with intelligent adaptive summarization\n\nand\n\nSmart T5 Large Audio to Professional Documents Converter\nUses: Whisper Large + FLAN-T5-Large\nOutputs: BRD, Purchase Order, and other business documents\nOptimized for Kaggle with GPU acceleration\n\"\"\"\n\nimport whisper\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport torch\nimport os\nimport gc\nimport re\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# ============================================================================\n# INSTALLATION (Run in Kaggle first cell):\n# !pip install -q openai-whisper transformers sentencepiece accelerate\n# ============================================================================\n\n\nclass SmartT5LargeDocumentGenerator:\n    \"\"\"\n    Intelligent T5-based audio summarizer with adaptive length control\n    Perfect for both short (30 sec) and long (3+ hours) audio \n    and +\n    Complete pipeline: Audio â†’ T5 Large Summary â†’ Professional Documents\n    Handles: BRD, Purchase Orders, Meeting Minutes, Technical Specs\n    \"\"\"\n    # Clear memory\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    def __init__(self, whisper_model=\"large\", t5_model = \"google/flan-t5-large\"):\n        \"\"\"\n        Initialize with T5 model\n        \n        Args:\n            whisper_model: 'tiny', 'base', 'small', 'medium', 'large'\n            t5_model: Choose from:\n                - 't5-small' (Fast, 60M params, good for short audio)\n                - 't5-base' (Balanced, 220M params, recommended)\n                - 't5-large' (Best quality, 770M params, slower)\n                - 't5-3b' (Highest quality, 3B params, very slow)\n                - 'google/flan-t5-base' (Instruction-tuned, excellent)\n                - 'google/flan-t5-large' (Best instruction-following)\n        \"\"\"\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        print(f\"ğŸ”§ Device: {self.device}\")\n        \n        if self.device == \"cuda\":\n            print(f\"ğŸš€ GPU: {torch.cuda.get_device_name(0)}\")\n            print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n        \n        \n        # Load Whisper large\n        print(f\"\\nğŸ“¥ Loading Whisper '{whisper_model}'...\")\n        self.whisper_model = whisper.load_model(whisper_model, device=self.device)\n        print(\"âœ… Whisper Large loaded!\")\n        \n        # Load T5\n        print(f\"\\nğŸ“¥ Loading T5 '{t5_model}'...\")\n        self.tokenizer = T5Tokenizer.from_pretrained(t5_model, legacy=False)\n\n        \n        self.model = T5ForConditionalGeneration.from_pretrained(\n            t5_model,\n            torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32\n        ).to(self.device)\n        print(\"âœ… T5 loaded!\")\n        \n        # Store model type for prefix handling\n        self.is_flan = \"flan\" in t5_model.lower()\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"âœ¨ Smart T5 Audio Summarizer Ready!\")\n        print(\"=\"*70 + \"\\n\")\n    \n    def transcribe_audio(self, audio_path):\n        \n        \"\"\"Transcribe multilingual audio to English\"\"\"\n        \n        if not os.path.exists(audio_path):\n            raise FileNotFoundError(f\"âŒ File not found: {audio_path}\")\n        \n        file_size = os.path.getsize(audio_path) / (1024 * 1024)\n        print(f\"ğŸµ Audio: {os.path.basename(audio_path)} ({file_size:.2f} MB)\")\n        print(f\"â³ Transcribing...\\n\")\n        \n        result = self.whisper_model.transcribe(\n            audio_path,\n            task='translate',\n            language=None,\n            fp16=self.device == \"cuda\",\n            verbose=False,\n            beam_size=5,\n            best_of=5,\n            temperature=0.0\n        )\n        \n        lang_map = {\n            'hi': 'Hindi (à¤¹à¤¿à¤¨à¥à¤¦à¥€)',\n            'en': 'English',\n            'mr': 'Marathi (à¤®à¤°à¤¾à¤ à¥€)'\n        }\n        \n        detected = result.get('language', 'unknown')\n        text = result['text'].strip()\n        word_count = len(text.split())\n        \n        print(f\"âœ… Transcription complete!\")\n        print(f\"ğŸŒ Language: {lang_map.get(detected, detected)}\")\n        print(f\"ğŸ“ Words: {word_count}\")\n        #print(f\"ğŸ“ Characters: {len(text)}\\n\")\n        \n        return {\n            'text': text,\n            'language': detected,\n            'language_name': lang_map.get(detected, detected),\n            'word_count': word_count\n        }\n    \n    def calculate_adaptive_summary_length(self, word_count, strategy):\n        \"\"\"\n        Intelligent adaptive summary length calculation\n        Optimized for T5 model (works for ANY audio length)\n        \n        Args:\n            word_count: Number of words in transcription\n            strategy: 'ultra_concise', 'concise', 'balanced', 'detailed', 'comprehensive'\n        \n        Returns:\n            dict with recommended parameters\n        \"\"\"\n        \n        # T5-optimized strategies\n        strategies = {\n            'ultra_concise': {\n                'base_ratio': 0.12,\n                'min_words': 12,\n                'max_words': 60,\n                'description': 'Single sentence summaries'\n            },\n            'concise': {\n                'base_ratio': 0.20,\n                'min_words': 20,\n                'max_words': 100,\n                'description': 'Brief, punchy summaries'\n            },\n            'balanced': {\n                'base_ratio': 0.30,\n                'min_words': 30,\n                'max_words': 180,\n                'description': 'Balanced detail and brevity'\n            },\n            'detailed': {\n                'base_ratio': 0.45,\n                'min_words': 50,\n                'max_words': 300,\n                'description': 'Comprehensive coverage'\n            },\n            'comprehensive': {\n                'base_ratio': 0.60,\n                'min_words': 80,\n                'max_words': 450,\n                'description': 'Extensive detail'\n            },\n            # âœ¨ NEW: HYBRID STRATEGY (detailed + comprehensive)\n            'hybrid': {\n                'base_ratio': 0.525,  # Average of 0.45 and 0.60\n                'min_words': 65,      # Average of 50 and 80\n                'max_words': 375,     # Average of 300 and 450\n                'description': 'Hybrid: detailed + comprehensive'\n            }\n        }\n        \n        config = strategies.get(strategy, strategies[strategy])\n        \n        # Adaptive calculation based on input length\n        if word_count < 40:\n            # Very short (< 30 seconds)\n            max_words = max(config['min_words'], int(word_count * 0.85))\n            min_words = max(8, int(word_count * 0.5))\n            ratio = 0.85\n            \n        elif word_count < 120:\n            # Short (30 sec - 1 min)\n            max_words = max(config['min_words'], int(word_count * 0.65))\n            min_words = max(12, int(word_count * 0.35))\n            ratio = 0.65\n            \n        elif word_count < 250:\n            # Medium short (1-2 min)\n            max_words = int(word_count * 0.50)\n            min_words = int(word_count * 0.25)\n            ratio = 0.50\n            \n        elif word_count < 600:\n            # Medium (2-5 min)\n            max_words = int(word_count * config['base_ratio'])\n            min_words = int(word_count * (config['base_ratio'] * 0.45))\n            ratio = config['base_ratio']\n            \n        elif word_count < 1500:\n            # Long (5-15 min)\n            max_words = int(word_count * (config['base_ratio'] * 0.95))\n            min_words = int(word_count * (config['base_ratio'] * 0.40))\n            ratio = config['base_ratio'] * 0.95\n            \n        elif word_count < 4000:\n            # Very long (15-45 min)\n            max_words = int(word_count * (config['base_ratio'] * 0.85))\n            min_words = int(word_count * (config['base_ratio'] * 0.35))\n            ratio = config['base_ratio'] * 0.85\n            \n        else:\n            # Extra long (45+ min)\n            max_words = int(word_count * (config['base_ratio'] * 0.75))\n            min_words = int(word_count * (config['base_ratio'] * 0.30))\n            ratio = config['base_ratio'] * 0.75\n        \n        # Apply strategy limits\n        max_words = min(max_words, config['max_words'])\n        max_words = max(max_words, config['min_words'])\n        \n        min_words = min(min_words, max_words - 8)\n        min_words = max(min_words, 8)\n        \n        # T5 uses tokens (roughly 1 word = 1.5 tokens)\n        max_tokens = int(max_words * 1.5)\n        min_tokens = int(min_words * 1.5)\n        \n        return {\n            'max_length': max_tokens,\n            'min_length': min_tokens,\n            'max_words': max_words,\n            'min_words': min_words,\n            'ratio': ratio,\n            'strategy': strategy,\n            'description': config['description']\n        }\n    \n    def generate_t5_summary(\n        self, \n        text, \n        max_length, \n        min_length, \n        quality,\n        custom_instruction=None\n    ):\n        \"\"\"\n        Generate abstractive summary using T5\n        \n        Args:\n            text: Input text\n            max_length: Maximum tokens\n            min_length: Minimum tokens\n            quality: 'fast', 'medium', 'high', 'best'\n            custom_instruction: Optional custom instruction for FLAN-T5\n        \"\"\"\n        \n        # Quality to num_beams mapping\n        beam_config = {\n            'fast': 2,\n            'medium': 4,\n            'high': 6,\n            'best': 10\n        }\n        num_beams = beam_config.get(quality, 10)\n        \n        # Prepare input with T5 prefix\n        if custom_instruction and self.is_flan:\n            # FLAN-T5 works better with instructions\n            input_text = f\"{custom_instruction}: {text}\"\n        else:\n            # Standard T5 prefix\n            input_text = f\"summarize: {text}\"\n        \n        # Tokenize\n        inputs = self.tokenizer(\n            input_text,\n            return_tensors=\"pt\",\n            max_length=512,  # T5 input limit\n            truncation=True,\n            padding=True\n        ).to(self.device)\n        \n        # Generate summary\n        with torch.no_grad():\n            summary_ids = self.model.generate(\n                inputs[\"input_ids\"],\n                max_length=max_length,\n                min_length=min_length,\n                num_beams=num_beams,\n                length_penalty=1.5,\n                early_stopping=True,\n                no_repeat_ngram_size=3,\n                repetition_penalty=1.2,\n                temperature=1.0\n            )\n        \n        # Decode\n        summary = self.tokenizer.decode(\n            summary_ids[0],\n            skip_special_tokens=True,\n            clean_up_tokenization_spaces=True\n        )\n        \n        return summary\n        \n    def extract_structured_info(self, summary_text):\n        \n        \"\"\"Extract structured information from summary\"\"\"\n        \n        info = {\n            'requirements': [],\n            'decisions': [],\n            'action_items': [],\n            'timeline': [],\n            'budget': [],\n            'risks': [],\n            'technical': [],\n            'deliverables': [],\n            'stakeholders': []\n        }\n        \n        sentences = re.split(r'[.!?]+', summary_text)\n        \n        for sentence in sentences:\n            sentence = sentence.strip()\n            if not sentence:\n                continue\n            \n            lower = sentence.lower()\n            \n            # Requirements\n            if any(w in lower for w in ['require', 'need', 'must', 'should', 'shall', 'expect']):\n                info['requirements'].append(sentence)\n            \n            # Decisions\n            if any(w in lower for w in ['decide', 'agreed', 'approved', 'confirmed', 'finalized']):\n                info['decisions'].append(sentence)\n            \n            # Action items\n            if any(w in lower for w in ['will', 'task', 'action', 'assign', 'responsible', 'owner']):\n                info['action_items'].append(sentence)\n            \n            # Timeline\n            if any(w in lower for w in ['deadline', 'timeline', 'date', 'week', 'month', 'schedule', 'due']):\n                info['timeline'].append(sentence)\n            \n            # Budget\n            if any(w in lower for w in ['cost', 'budget', 'price', 'payment', 'fund', 'expense', '$', 'rs', 'rupee', 'inr']):\n                info['budget'].append(sentence)\n            \n            # Risks\n            if any(w in lower for w in ['risk', 'concern', 'issue', 'challenge', 'problem', 'blocker']):\n                info['risks'].append(sentence)\n            \n            # Technical\n            if any(w in lower for w in ['technical', 'technology', 'system', 'platform', 'api', 'database', 'infrastructure']):\n                info['technical'].append(sentence)\n            \n            # Deliverables\n            if any(w in lower for w in ['deliver', 'output', 'product', 'feature', 'component', 'milestone']):\n                info['deliverables'].append(sentence)\n            \n            # Stakeholders\n            if any(w in lower for w in ['stakeholder', 'team', 'department', 'client', 'customer', 'vendor']):\n                info['stakeholders'].append(sentence)\n        \n        return info\n\n    def generate_brd(self, summary_text, structured_info, metadata):\n        \"\"\"Generate Business Requirements Document\"\"\"\n        \n        doc = f\"\"\"\n{'='*80}\nBUSINESS REQUIREMENTS DOCUMENT (BRD)\n{'='*80}\n\nDocument Information:\n--------------------\nProject Name:     {metadata.get('project_name', 'Audio Extracted Project')}\nDocument Date:    {metadata.get('date', datetime.now().strftime('%Y-%m-%d'))}\nVersion:          {metadata.get('version', '1.0')}\nPrepared By:      {metadata.get('author', 'T5 Large Audio Analysis System')}\nStatus:           {metadata.get('status', 'Draft - Extracted from Audio')}\nDepartment:       {metadata.get('department', 'TBD')}\nSponsor:          {metadata.get('sponsor', 'TBD')}\n\n\n1. EXECUTIVE SUMMARY\n{'='*80}\n\n{summary_text}\n\n\n2. BUSINESS OBJECTIVES\n{'='*80}\n\nBased on the audio discussion, the key business objectives are:\n\n\"\"\"\n        \n        # Add objectives from summary\n        if structured_info['requirements']:\n            for idx, req in enumerate(structured_info['requirements'][:5], 1):\n                doc += f\"OBJ-{idx}: {req}\\n\"\n        else:\n            doc += \"Business objectives to be refined based on stakeholder review.\\n\"\n        \n        doc += f\"\"\"\n\n3. BUSINESS REQUIREMENTS\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['requirements']:\n            for idx, req in enumerate(structured_info['requirements'], 1):\n                doc += f\"BR-{idx:03d}: {req}\\n\"\n                doc += f\"         Priority: {metadata.get('priority', 'Medium')}\\n\"\n                doc += f\"         Status: New\\n\"\n                doc += f\"         Source: Audio Discussion\\n\\n\"\n        else:\n            doc += \"Business requirements extracted from executive summary above.\\n\"\n        \n        doc += f\"\"\"\n\n4. FUNCTIONAL REQUIREMENTS\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['technical']:\n            for idx, tech in enumerate(structured_info['technical'], 1):\n                doc += f\"FR-{idx:03d}: {tech}\\n\"\n                doc += f\"         Category: {metadata.get('category', 'Technical')}\\n\"\n                doc += f\"         Priority: {metadata.get('priority', 'Medium')}\\n\\n\"\n        else:\n            doc += \"Functional requirements to be detailed in technical specification.\\n\"\n        \n        doc += f\"\"\"\n\n5. STAKEHOLDERS\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['stakeholders']:\n            doc += \"Stakeholders identified in discussion:\\n\\n\"\n            for stakeholder in structured_info['stakeholders']:\n                doc += f\"â€¢ {stakeholder}\\n\"\n        else:\n            doc += f\"\"\"\nPrimary Stakeholders:\nâ€¢ Project Sponsor: {metadata.get('sponsor', 'TBD')}\nâ€¢ Business Owner: {metadata.get('business_owner', 'TBD')}\nâ€¢ Project Manager: {metadata.get('pm', 'TBD')}\nâ€¢ End Users: {metadata.get('end_users', 'As discussed in audio')}\n\"\"\"\n        \n        doc += f\"\"\"\n\n6. KEY DECISIONS\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['decisions']:\n            for idx, decision in enumerate(structured_info['decisions'], 1):\n                doc += f\"D{idx}. {decision}\\n\"\n                doc += f\"    Date: {metadata.get('date', 'TBD')}\\n\"\n                doc += f\"    Decision Maker: {metadata.get('decision_maker', 'TBD')}\\n\\n\"\n        else:\n            doc += \"Key decisions documented in executive summary.\\n\"\n        \n        doc += f\"\"\"\n\n7. SCOPE\n{'='*80}\n\nIn Scope:\n\"\"\"\n        \n        if structured_info['deliverables']:\n            for deliverable in structured_info['deliverables']:\n                doc += f\"â€¢ {deliverable}\\n\"\n        else:\n            doc += \"â€¢ As defined in requirements above\\n\"\n        \n        doc += \"\"\"\n\nOut of Scope:\nâ€¢ Items not mentioned in the audio discussion\nâ€¢ Features to be considered for future phases\n\n\"\"\"\n        \n        doc += f\"\"\"\n\n8. TIMELINE & MILESTONES\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['timeline']:\n            for milestone in structured_info['timeline']:\n                doc += f\"â€¢ {milestone}\\n\"\n        else:\n            doc += f\"\"\"\nProject Timeline:\nâ€¢ Requirements Phase: {metadata.get('req_phase', 'TBD')}\nâ€¢ Design Phase: {metadata.get('design_phase', 'TBD')}\nâ€¢ Development Phase: {metadata.get('dev_phase', 'TBD')}\nâ€¢ Testing Phase: {metadata.get('test_phase', 'TBD')}\nâ€¢ Deployment: {metadata.get('deployment', 'TBD')}\n\"\"\"\n        \n        doc += f\"\"\"\n\n9. BUDGET & RESOURCES\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['budget']:\n            for budget_item in structured_info['budget']:\n                doc += f\"â€¢ {budget_item}\\n\"\n        else:\n            doc += f\"\"\"\nEstimated Budget: {metadata.get('budget', 'To be determined')}\n\nResource Requirements:\nâ€¢ Team Size: {metadata.get('team_size', 'TBD')}\nâ€¢ Duration: {metadata.get('duration', 'TBD')}\nâ€¢ External Resources: {metadata.get('external_resources', 'TBD')}\n\"\"\"\n        \n        doc += f\"\"\"\n\n10. RISKS & ASSUMPTIONS\n{'='*80}\n\nRisks Identified:\n\"\"\"\n        \n        if structured_info['risks']:\n            for idx, risk in enumerate(structured_info['risks'], 1):\n                doc += f\"{idx}. {risk}\\n\"\n                doc += f\"   Impact: {metadata.get('risk_impact', 'Medium')}\\n\"\n                doc += f\"   Mitigation: To be defined\\n\\n\"\n        else:\n            doc += \"Risk assessment to be conducted during project planning.\\n\"\n        \n        doc += \"\"\"\n\nAssumptions:\nâ€¢ Resources will be available as per project timeline\nâ€¢ Stakeholder approvals will be obtained in timely manner\nâ€¢ Technical infrastructure is available and ready\n\n\"\"\"\n        \n        doc += f\"\"\"\n\n11. DEPENDENCIES\n{'='*80}\n\nâ€¢ Dependencies identified in audio discussion\nâ€¢ External systems and integrations as required\nâ€¢ Third-party services and vendors as needed\n\n\n12. SUCCESS CRITERIA\n{'='*80}\n\nThe project will be considered successful when:\n\nâ€¢ All business requirements are met\nâ€¢ System is deployed and operational\nâ€¢ User acceptance testing is completed successfully\nâ€¢ Stakeholders sign off on deliverables\n\n\n13. APPROVAL\n{'='*80}\n\nThis document has been reviewed and approved by:\n\n\nBusiness Owner: _____________________    Date: ___________\n\nSignature:      _____________________\n\n\nProject Sponsor: ____________________    Date: ___________\n\nSignature:       ____________________\n\n\n{'='*80}\nDocument Generated from Audio Analysis using Whisper Large + FLAN-T5 Large\nGenerated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n{'='*80}\n\"\"\"\n        \n        return doc\n    \n    def generate_purchase_order(self, summary_text, structured_info, metadata):\n        \"\"\"Generate Purchase Order\"\"\"\n        \n        doc = f\"\"\"\n{'='*80}\nPURCHASE ORDER\n{'='*80}\n\nPO Number:        {metadata.get('po_number', 'PO-' + datetime.now().strftime('%Y%m%d-%H%M'))}\nDate:             {metadata.get('date', datetime.now().strftime('%Y-%m-%d'))}\nStatus:           {metadata.get('status', 'Draft - Extracted from Audio')}\n\n\nVENDOR INFORMATION:\n{'='*80}\nVendor Name:      {metadata.get('vendor_name', 'TBD - As per audio discussion')}\nVendor Code:      {metadata.get('vendor_code', 'TBD')}\nAddress:          {metadata.get('vendor_address', 'TBD')}\nCity/State/ZIP:   {metadata.get('vendor_location', 'TBD')}\nContact Person:   {metadata.get('vendor_contact', 'TBD')}\nPhone:            {metadata.get('vendor_phone', 'TBD')}\nEmail:            {metadata.get('vendor_email', 'TBD')}\nGST/Tax ID:       {metadata.get('vendor_gst', 'TBD')}\n\n\nBUYER INFORMATION:\n{'='*80}\nCompany Name:     {metadata.get('company_name', 'Your Company Ltd.')}\nDepartment:       {metadata.get('department', 'Procurement')}\nAddress:          {metadata.get('buyer_address', 'TBD')}\nCity/State/ZIP:   {metadata.get('buyer_location', 'TBD')}\nContact Person:   {metadata.get('buyer_contact', metadata.get('author', 'TBD'))}\nPhone:            {metadata.get('buyer_phone', 'TBD')}\nEmail:            {metadata.get('buyer_email', 'TBD')}\n\n\nPURCHASE ORDER SUMMARY:\n{'='*80}\n\nBased on Audio Discussion:\n{summary_text}\n\n\nDETAILED LINE ITEMS:\n{'='*80}\n\n\"\"\"\n        \n        # Extract items from deliverables or requirements\n        items = structured_info['deliverables'] if structured_info['deliverables'] else structured_info['requirements']\n        \n        doc += f\"{'Item':<5} {'Description':<45} {'Qty':<8} {'Unit':<10} {'Price':<12} {'Total':<12}\\n\"\n        doc += \"-\" * 100 + \"\\n\"\n        \n        if items:\n            for idx, item in enumerate(items[:15], 1):  # Max 15 items\n                clean_item = item.replace('\\n', ' ')[:42]\n                doc += f\"{idx:<5} {clean_item:<45} {'TBD':<8} {'Each':<10} {'TBD':<12} {'TBD':<12}\\n\"\n        else:\n            doc += f\"{'1':<5} {'Items/Services as per audio discussion':<45} {'TBD':<8} {'Each':<10} {'TBD':<12} {'TBD':<12}\\n\"\n        \n        doc += \"\\n\"\n        \n        doc += f\"\"\"\n\nCOST BREAKDOWN:\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['budget']:\n            doc += \"Cost Details (from audio discussion):\\n\\n\"\n            for budget_item in structured_info['budget']:\n                doc += f\"â€¢ {budget_item}\\n\"\n            doc += \"\\n\"\n        \n        doc += f\"\"\"\nSubtotal:                                                    {metadata.get('subtotal', 'TBD')}\nDiscount (if any):                                           {metadata.get('discount', '0.00')}\n                                                             ___________\nSubtotal after Discount:                                     {metadata.get('subtotal_after_discount', 'TBD')}\n\nTax/GST ({metadata.get('tax_rate', '18')}%):                                             {metadata.get('tax_amount', 'TBD')}\nShipping & Handling:                                         {metadata.get('shipping', 'TBD')}\nOther Charges:                                               {metadata.get('other_charges', '0.00')}\n                                                             ___________\nTOTAL AMOUNT:                                                {metadata.get('total_amount', 'TBD')}\n                                                             ===========\n\n\nTERMS & CONDITIONS:\n{'='*80}\n\nPayment Terms:         {metadata.get('payment_terms', 'Net 30 Days')}\nDelivery Terms:        {metadata.get('delivery_terms', 'FOB Destination')}\nExpected Delivery:     {metadata.get('delivery_date', 'TBD - As per discussion')}\nDelivery Address:      {metadata.get('delivery_address', 'As per buyer information above')}\nShipping Method:       {metadata.get('shipping_method', 'Standard')}\nWarranty:              {metadata.get('warranty', 'As per vendor terms')}\nReturn Policy:         {metadata.get('return_policy', 'As per vendor terms')}\n\n\nPAYMENT SCHEDULE:\n{'='*80}\n\n\"\"\"\n        \n        if metadata.get('payment_schedule'):\n            doc += metadata['payment_schedule']\n        else:\n            doc += f\"\"\"\nâ€¢ Advance Payment: {metadata.get('advance_payment', '0%')} on PO confirmation\nâ€¢ Balance Payment: {metadata.get('balance_payment', '100%')} {metadata.get('payment_terms', 'Net 30')}\n\"\"\"\n        \n        doc += f\"\"\"\n\nSPECIAL INSTRUCTIONS:\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['requirements']:\n            doc += \"Requirements from audio discussion:\\n\\n\"\n            for req in structured_info['requirements'][:5]:\n                doc += f\"â€¢ {req}\\n\"\n        else:\n            doc += \"As per audio discussion and mutual agreement.\\n\"\n        \n        doc += f\"\"\"\n\nADDITIONAL NOTES:\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['action_items']:\n            doc += \"Action Items:\\n\\n\"\n            for action in structured_info['action_items'][:5]:\n                doc += f\"â€¢ {action}\\n\"\n        \n        doc += f\"\"\"\n\nVALIDITY:\n{'='*80}\n\nThis Purchase Order is valid until: {metadata.get('validity_date', 'TBD')}\n\n\nAPPROVAL & AUTHORIZATION:\n{'='*80}\n\nRequested By:\n\nName:      {metadata.get('requested_by', 'TBD')}\nTitle:     {metadata.get('requested_title', 'TBD')}\nDate:      {metadata.get('date', 'TBD')}\nSignature: _____________________\n\n\nApproved By:\n\nName:      {metadata.get('approved_by', 'TBD')}\nTitle:     {metadata.get('approved_title', 'Manager/Director')}\nDate:      ___________\nSignature: _____________________\n\n\nFinance Approval:\n\nName:      {metadata.get('finance_approval', 'TBD')}\nTitle:     Finance Manager\nDate:      ___________\nSignature: _____________________\n\n\nVENDOR ACCEPTANCE:\n{'='*80}\n\nWe accept the terms and conditions of this Purchase Order:\n\nVendor Name:    {metadata.get('vendor_name', 'TBD')}\nAuthorized By:  _____________________\nTitle:          _____________________\nDate:           ___________\nSignature:      _____________________\nCompany Seal:   \n\n\n{'='*80}\nPurchase Order Generated from Audio Analysis\nSystem: Whisper Large + FLAN-T5 Large\nGenerated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n{'='*80}\n\nIMPORTANT NOTES:\n- This is a preliminary document extracted from audio discussion\n- Please review and verify all details before finalization\n- TBD items must be filled in before final approval\n- Consult legal/procurement team for compliance review\n\"\"\"\n        \n        return doc\n\n    def process_audio_smart(\n        self,\n        audio_path,\n        strategy,\n        quality,\n        custom_instruction=None,\n        save_output=True,\n        output_filename=None\n    ):\n        \"\"\"\n        Complete smart pipeline with T5 adaptive summarization\n        \n        Args:\n            audio_path: Path to audio file\n            strategy: 'ultra_concise', 'concise', 'balanced', 'detailed', 'comprehensive'\n            quality: 'fast', 'medium', 'high', 'best'\n            custom_instruction: Optional instruction for FLAN-T5\n                               e.g., \"Summarize the key business points\"\n            save_output: Save results to file\n        \"\"\"\n        \n        \n        print(\"=\"*70)\n        print(\"ğŸ¯ SMART T5 AUDIO SUMMARIZER\")\n        print(\"=\"*70 + \"\\n\")\n        \n        \n        # Step 1: Transcribe\n        transcription = self.transcribe_audio(audio_path)\n        word_count = transcription['word_count']\n        \n        # Step 2: Calculate smart summary length\n        print(f\"ğŸ§  Calculating adaptive summary length...\")\n        summary_config = self.calculate_adaptive_summary_length(word_count, strategy)\n        \n        print(f\"ğŸ“Š Strategy: {summary_config['strategy'].upper()}\")\n        print(f\"ğŸ“ Description: {summary_config['description']}\")\n        print(f\"ğŸ“ Input: {word_count} words\")\n        print(f\"ğŸ“ Target: {summary_config['min_words']}-{summary_config['max_words']} words\")\n        print(f\"ğŸ“‰ Compression: {summary_config['ratio']*100:.0f}%\")\n        print(f\"âš¡ Quality: {quality.upper()}\\n\")\n        \n        if custom_instruction:\n            print(f\"ğŸ’¬ Custom Instruction: {custom_instruction}\\n\")\n        \n        # Step 3: Handle very short text\n        if word_count < 25:\n            print(\"âš ï¸ Text very short (<25 words) - returning full transcription\\n\")\n            summary = transcription['text']\n            summary_words = word_count\n        \n        # Step 4: Summarize with T5\n        else:\n            print(f\"ğŸ“Š Generating T5 summary (process_audio_smart)...\")\n            \n            # For long texts, use chunking\n            if word_count > 400:\n                summary = self._summarize_long_text(\n                    transcription['text'],\n                    summary_config,\n                    quality,\n                    custom_instruction\n                )\n            else:\n                summary = self.generate_t5_summary(\n                    transcription['text'],\n                    max_length=summary_config['max_length'],\n                    min_length=summary_config['min_length'],\n                    quality=quality,\n                    custom_instruction=custom_instruction\n                )\n            \n            summary_words = len(summary.split())\n            print(f\"âœ… Summary generated! ({summary_words} words)\\n\")\n        \n        # Prepare results\n        results = {\n            'audio_file': os.path.basename(audio_path),\n            'language': transcription['language_name'],\n            'transcription': transcription['text'],\n            'summary': summary,\n            'input_words': word_count,\n            'summary_words': summary_words,\n            'compression_ratio': (1 - summary_words/word_count) * 100 if word_count > 0 else 0,\n            'strategy': strategy,\n            'quality': quality,\n            'config': summary_config,\n            'custom_instruction': custom_instruction\n        }\n\n    # Display results\n        self._display_results(results)\n    \n    # Save results\n        if save_output:\n            self._save_results(results, custom_filename=output_filename)\n    \n    # âœ… ADD THIS: Return the results!\n        return results\n\n    def process_audio_to_document(\n        self,\n        audio_path,           \n        summary_text,\n        document_type='brd',\n        custom_instruction=None,\n        metadata=None,\n        save_output=True,\n        output_filename=None\n    ):\n        \"\"\"\n        Complete pipeline: not Audio â†’ Summary â†’ Document\n        \n        Args:\n            audio_path: Path to audio file\n            document_type: 'brd' or 'purchase_order'\n            custom_instruction: Custom instruction for T5\n            metadata: Document metadata\n        \n        Returns:\n            dict with transcription, summary, and formatted document\n        \"\"\"\n        \n        print(\"=\"*70)\n        print(f\"AUDIO TO {document_type.upper()} CONVERTER\")\n        print(\"=\"*70 + \"\\n\")\n        \n        \"\"\" Step 1: Transcribe\n        print(\"STEP 1: Transcribing with Whisper Large...\")\n        transcription = self.transcribe_audio(audio_path)\n        \n         Step 2: Generate Summary\n        print(\"STEP 2: Generating summary with FLAN-T5 Large...\")\n        summary = self.generate_summary(\n            transcription['text'],\n            custom_instruction=custom_instruction\n        \n\n        summary = self.process_audio_smart(audio_path,\n            strategy,\n            quality,\n            custom_instruction=None,\n            save_output=True,\n            output_filename=None))\"\"\"\n        \n        # Step 3: Extract structured information\n        print(\"STEP 3: Extracting structured information...\")\n        structured_info = self.extract_structured_info(summary_text)\n        \n        # Step 4: Generate document\n        print(f\"STEP 4: Generating {document_type.upper()}...\\n\")\n        \n        if metadata is None:\n            metadata = {}\n        \n        metadata.setdefault('project_name', os.path.basename(audio_path).split('.')[0])\n        metadata.setdefault('date', datetime.now().strftime('%Y-%m-%d'))\n        \n        if document_type == 'brd':\n            formatted_doc = self.generate_brd(summary_text, structured_info, metadata)\n        elif document_type == 'purchase_order':\n            formatted_doc = self.generate_purchase_order(summary_text, structured_info, metadata)\n        else:\n            raise ValueError(f\"Unknown document type: {document_type}\")\n        \n        # Step 5: Save\n        output_filename = f\"/kaggle/working/{document_type}_{metadata['project_name']}.txt\"\n        with open(output_filename, 'w', encoding='utf-8') as f:\n            f.write(formatted_doc)\n        \n        print(f\"âœ… {document_type.upper()} generated and saved!\")\n        print(f\"ğŸ“ File: {output_filename}\\n\")\n        \n        return {\n            'structured_info': structured_info,\n            'formatted_document': formatted_doc,\n            'output_file': output_filename\n        }\n\n        return results\n\n    # Display results\n        self._display_results(results)\n        \n        # Save results\n        if save_output:\n            self._save_results(results, custom_filename=output_filename)\n        \n    \n    def _summarize_long_text(self, text, summary_config, quality, custom_instruction):\n        \"\"\"Handle long texts with intelligent chunking\"\"\"\n        # T5 handles ~400 words well per chunk\n        chunk_size = 400  # words\n        words = text.split()\n        chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n        \n        print(f\"  ğŸ“„ Processing {len(chunks)} chunk(s)...\")\n        \n        chunk_summaries = []\n        for idx, chunk in enumerate(chunks):\n            chunk_words = len(chunk.split())\n            \n            if chunk_words < 25:\n                continue\n            \n            # Adaptive length per chunk\n            chunk_config = self.calculate_adaptive_summary_length(\n                chunk_words,\n                summary_config['strategy']\n            )\n            \n            print(f\"    â¤ Chunk {idx+1}/{len(chunks)} ({chunk_words} words)...\", end=\" \")\n            \n            try:\n                chunk_summary = self.generate_t5_summary(\n                    chunk,\n                    max_length=chunk_config['max_length'],\n                    min_length=chunk_config['min_length'],\n                    quality=quality,\n                    custom_instruction=custom_instruction\n                )\n                chunk_summaries.append(chunk_summary)\n                print(\"âœ“\")\n            except Exception as e:\n                print(f\"âœ— (Error: {str(e)[:30]})\")\n                continue\n        \n        if not chunk_summaries:\n            return text[:500]\n        \n        combined = ' '.join(chunk_summaries)\n        combined_words = len(combined.split())\n        \n        # Final summary if still too long\n        if len(chunks) > 1 and combined_words > summary_config['max_words']:\n            print(f\"  â¤ Creating final summary ({combined_words} words)...\", end=\" \")\n            try:\n                final = self.generate_t5_summary(\n                    combined,\n                    max_length=summary_config['max_length'],\n                    min_length=summary_config['min_length'],\n                    quality=quality,\n                    custom_instruction=custom_instruction\n                )\n                print(\"âœ“\")\n                return final\n            except:\n                print(\"âœ—\")\n        \n        return combined\n    \n    def _display_results(self, results):\n        \"\"\"Display formatted results\"\"\"\n        print(\"=\"*70)\n        print(\"ğŸ“‹ RESULTS\")\n        print(\"=\"*70)\n        print(f\"ğŸ“ File: {results['audio_file']}\")\n        print(f\"ğŸŒ Language: {results['language']}\")\n        print(f\"ğŸ“Š strategy: {results['strategy'].upper()}\")\n        print(f\"âš¡ Quality: {results['quality'].upper()}\")\n        if results.get('custom_instruction'):\n            print(f\"ğŸ’¬ Instruction: {results['custom_instruction']}\")\n        print(f\"ğŸ“ Original: {results['input_words']} words\")\n        print(f\"ğŸ“ Summary: {results['summary_words']} words\")\n        print(f\"ğŸ“‰ Compression: {results['compression_ratio']:.1f}%\")\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"âœ¨ T5 ABSTRACTIVE SUMMARY:\")\n        print(\"=\"*70)\n        print(results['summary'])\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"ğŸ“„ FULL TRANSCRIPTION (first 400 chars):\")\n        print(\"=\"*70)\n        print(results['transcription'][:400] + \"...\")\n        print(\"=\"*70 + \"\\n\")\n    \n    def _save_results(self, results, custom_filename=None):\n        \"\"\"Save to file with optional custom filename\"\"\"\n\n        # Use custom filename if provided, otherwise use default\n        if custom_filename:\n            output_file = f\"/kaggle/working/{custom_filename}\"\n        else:\n            output_file = \"/kaggle/working/t5_best_smart_summary.txt\"\n        \n        with open(output_file, 'w', encoding='utf-8') as f:\n            f.write(\"=\"*70 + \"\\n\")\n            f.write(\"SMART T5 AUDIO SUMMARY REPORT\\n\")\n            f.write(\"=\"*70 + \"\\n\\n\")\n            f.write(f\"Audio File: {results['audio_file']}\\n\")\n            f.write(f\"Language: {results['language']}\\n\")\n            #f.write(f\"Models: {results['models']}\\n\")\n            f.write(f\"Strategy: {results['strategy']}\\n\")\n            f.write(f\"Quality: {results['quality']}\\n\")\n            if results.get('custom_instruction'):\n                f.write(f\"Custom Instruction: {results['custom_instruction']}\\n\")\n            f.write(f\"Original Words: {results['input_words']}\\n\")\n            f.write(f\"Summary Words: {results['summary_words']}\\n\")\n            f.write(f\"Compression: {results['compression_ratio']:.1f}%\\n\\n\")\n            f.write(\"=\"*70 + \"\\n\")\n            f.write(\"T5 ABSTRACTIVE SUMMARY:\\n\")\n            f.write(\"=\"*70 + \"\\n\\n\")\n            f.write(results['summary'] + \"\\n\\n\")\n            f.write(\"=\"*70 + \"\\n\")\n            f.write(\"FULL TRANSCRIPTION:\\n\")\n            f.write(\"=\"*70 + \"\\n\\n\")\n            f.write(results['transcription'] + \"\\n\")\n        \n        print(f\"ğŸ’¾ Saved to: {output_file}\\n\")\n\n        \"\"\"\n        Initialize with T5 model\n        \n        Args:\n            whisper_model: 'tiny', 'base', 'small', 'medium', 'large'\n            t5_model: Choose from:\n                - 't5-small' (Fast, 60M params, good for short audio)\n                - 't5-base' (Balanced, 220M params, recommended)\n                - 't5-large' (Best quality, 770M params, slower)\n                - 't5-3b' (Highest quality, 3B params, very slow)\n                - 'google/flan-t5-base' (Instruction-tuned, excellent)\n                - 'google/flan-t5-large' (Best instruction-following)\n\n            Args:\n            word_count: Number of words in transcription\n            strategy: 'ultra_concise', 'concise', 'balanced', 'detailed', 'comprehensive'\n        \n        \"\"\"\n# Test that class is defined\nprint(\"âœ… SmartT5LargeDocumentGenerator class defined successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:29:38.622039Z","iopub.execute_input":"2025-12-12T09:29:38.622356Z","iopub.status.idle":"2025-12-12T09:30:14.293420Z","shell.execute_reply.started":"2025-12-12T09:29:38.622326Z","shell.execute_reply":"2025-12-12T09:30:14.292770Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stderr","text":"2025-12-12 09:29:55.496217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765531795.671858      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765531795.721429      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"âœ… SmartT5LargeDocumentGenerator class defined successfully!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# USAGE EXAMPLES\n# ============================================================================\nimport gc\nif __name__ == \"__main__\":\n\n    # ========================================================================\n    # STEP 1: Load Models ONCE\n    # ========================================================================\n    \n    \n    # ========================================================================\n    #  Audio --- Sumamry --- Document\n    # ========================================================================\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"INITIALIZING T5 LARGE DOCUMENT GENERATOR\")\n    print(\"=\"*70 + \"\\n\")\n\n    # Clear memory\n    torch.cuda.empty_cache()\n    gc.collect()  \n    \n        \n    summarizer = SmartT5LargeDocumentGenerator(\n        whisper_model=\"large\",\n        t5_model=\"google/flan-t5-large\"  # Instruction-tuned T5\n        )\n\n    audio_path=\"/kaggle/input/eng-hinbi-marathi-mix-audio/Random recording for ReqGen.m4a\"\n    \n   # Create a unique filename using the current strategy name in the loop.\n    # We use .replace('_', '-') for cleaner filenames if needed, but it works fine as is.\n    t5_model=\"google/flan-t5-large\"\n    strategy=\"comprehensive\"\n    quality=\"best\"\n    safe_model_name = t5_model.replace('/', '_') \n    dynamic_output_filename = f\"Summary_{safe_model_name}_{strategy}_{quality}-random-meeting.txt\"\n    # === END DYNAMIC FILENAME CHANGE ===\n\n    results = summarizer.process_audio_smart(\n        audio_path = audio_path,\n        strategy=\"comprehensive\",\n        quality=\"best\", \n        save_output=True,\n        output_filename=dynamic_output_filename\n        )\n\n    print(f\"Saving output to: /kaggle/working/{dynamic_output_filename}\")\n\n    # ========================================================================\n    # EXAMPLE 1: Generate BRD from Audio\n    # ========================================================================\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"EXAMPLE 1: GENERATE BRD FROM AUDIO\")\n    print(\"=\"*70 + \"\\n\")\n\n    brd_output_filename = f\"Summary_{safe_model_name}_{strategy}_{quality}_brd-random-meeting.txt\"\n    \n    \n    brd_results = summarizer.process_audio_to_document(\n        audio_path=audio_path,\n        summary_text=results['summary'],\n        document_type='brd',\n        custom_instruction=\"Extract all business requirements, decisions, timeline, and stakeholder information\",\n        metadata={\n            'project_name': 'Mobile_App_Redesign',\n            'version': '1.0',\n            'status': 'Draft',\n            'author': 'Business Analysis Team',\n            'department': 'Product Development',\n            'sponsor': 'VP of Product',\n            'priority': 'High'\n        },\n        save_output=True,\n        output_filename=brd_output_filename\n    )\n    \n    #print(\"BRD Summary Preview:\")\n    #print(brd_results['summary_text'][:300] + \"...\\n\")\n\n    # ========================================================================\n    # EXAMPLE 2: Generate Purchase Order from Audio\n    # ========================================================================\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"EXAMPLE 2: GENERATE PURCHASE ORDER FROM AUDIO\")\n    print(\"=\"*70 + \"\\n\")\n\n    po_output_filename = f\"Summary_{safe_model_name}_{strategy}_{quality}_po-random-meeting.txt\"\n\n    po_results = summarizer.process_audio_to_document(\n        audio_path=audio_path,\n        summary_text=results['summary'],\n        document_type='purchase_order',\n        custom_instruction=\"Extract vendor details, items to be purchased, quantities, costs, and delivery terms\",\n        metadata={\n            'po_number': 'PO-2024-001',\n            'vendor_name': 'ABC Technology Solutions Pvt Ltd',\n            'vendor_address': '123 Tech Park, Bangalore',\n            'vendor_contact': 'Mr. Rajesh Kumar',\n            'vendor_phone': '+91 98765 43210',\n            'vendor_email': 'rajesh@abctech.com',\n            'vendor_gst': '29ABCDE1234F1Z5',\n            'company_name': 'XYZ Enterprises Ltd',\n            'department': 'IT Procurement',\n            'payment_terms': 'Net 30 Days',\n            'delivery_date': '2024-02-15',\n            'shipping_method': 'Express Delivery',\n            'tax_rate': '18'\n        },\n        save_output=True,\n        output_filename=po_output_filename\n    )\n    \n    #print(\"PO Summary Preview:\")\n    #print(po_results['summary_text'][:300] + \"...\\n\")\n    \n    \n# Clear memory after processing\n    del results\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:30:16.989567Z","iopub.execute_input":"2025-12-12T09:30:16.990761Z","iopub.status.idle":"2025-12-12T09:33:13.540890Z","shell.execute_reply.started":"2025-12-12T09:30:16.990701Z","shell.execute_reply":"2025-12-12T09:33:13.540076Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"\n======================================================================\nINITIALIZING T5 LARGE DOCUMENT GENERATOR\n======================================================================\n\nğŸ”§ Device: cuda\nğŸš€ GPU: Tesla T4\nğŸ’¾ GPU Memory: 15.83 GB\n\nğŸ“¥ Loading Whisper 'large'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.88G/2.88G [00:51<00:00, 59.9MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… Whisper Large loaded!\n\nğŸ“¥ Loading T5 'google/flan-t5-large'...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e5a6c9bc6394f84aac471012be30900"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3600e583325d42158f0004fe6ba1eec0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fdb0fd275f345529ef76cece07b8bf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b9d32151ca041d9bead4d70ca14d680"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9996265076f64f0a9b2b031427c860d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a574b4c010164846afb150ee3893b6cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5967a5eaa844c23b519d30e541e8436"}},"metadata":{}},{"name":"stdout","text":"âœ… T5 loaded!\n\n======================================================================\nâœ¨ Smart T5 Audio Summarizer Ready!\n======================================================================\n\n======================================================================\nğŸ¯ SMART T5 AUDIO SUMMARIZER\n======================================================================\n\nğŸµ Audio: Random recording for ReqGen.m4a (0.65 MB)\nâ³ Transcribing...\n\nDetected language: English\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15577/15577 [01:09<00:00, 223.39frames/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… Transcription complete!\nğŸŒ Language: English\nğŸ“ Words: 607\nğŸ§  Calculating adaptive summary length...\nğŸ“Š Strategy: COMPREHENSIVE\nğŸ“ Description: Extensive detail\nğŸ“ Input: 607 words\nğŸ“ Target: 145-345 words\nğŸ“‰ Compression: 57%\nâš¡ Quality: BEST\n\nğŸ“Š Generating T5 summary (process_audio_smart)...\n  ğŸ“„ Processing 2 chunk(s)...\n    â¤ Chunk 1/2 (400 words)... âœ“\n    â¤ Chunk 2/2 (207 words)... âœ“\nâœ… Summary generated! (233 words)\n\n======================================================================\nğŸ“‹ RESULTS\n======================================================================\nğŸ“ File: Random recording for ReqGen.m4a\nğŸŒ Language: English\nğŸ“Š strategy: COMPREHENSIVE\nâš¡ Quality: BEST\nğŸ“ Original: 607 words\nğŸ“ Summary: 233 words\nğŸ“‰ Compression: 61.6%\n\n======================================================================\nâœ¨ T5 ABSTRACTIVE SUMMARY:\n======================================================================\ntoday's topic of our discussion will be on business card detection right so the agenda in discussing this project is that we have to detect the business card from a given video this person's card name the company in which he's working the designation the person is at the address of the company or the office the phone number the email address so details like these needs to be extracted from the video so we need to discuss on how can we do it. The business card can be used for this project and then after that we will apply the information extraction for the modules or models we will use to detect th ebusiness card from [a] given video or image [b] and then afterwards we'll apply the following information extraction: the name of the person whose business card we are going to detect, the company where he is working, the designation, the location of the place of work, the telephone number, the email Identify the modules or models we will use to detect the business card from a given video or image and then after that we will apply the information extraction for the module or models We will Apply the Information Extraction For The Modules Or Models We Will Use To Detect The Business Card From A Given Video Or Image And Then After That We Will Apply The Information\n\n======================================================================\nğŸ“„ FULL TRANSCRIPTION (first 400 chars):\n======================================================================\nhello everyone good morning I hope I am audible to everyone today's topic of our discussion will be on business card detection right so the agenda in discussing this project is that we have to detect the business card from a given video this person's card name the company in which he's working the designation the person is at the address of the company or the office the phone number the email addr...\n======================================================================\n\nğŸ’¾ Saved to: /kaggle/working/Summary_google_flan-t5-large_comprehensive_best-random-meeting.txt\n\nSaving output to: /kaggle/working/Summary_google_flan-t5-large_comprehensive_best-random-meeting.txt\n\n======================================================================\nEXAMPLE 1: GENERATE BRD FROM AUDIO\n======================================================================\n\n======================================================================\nAUDIO TO BRD CONVERTER\n======================================================================\n\nSTEP 3: Extracting structured information...\nSTEP 4: Generating BRD...\n\nâœ… BRD generated and saved!\nğŸ“ File: /kaggle/working/brd_Mobile_App_Redesign.txt\n\n\n======================================================================\nEXAMPLE 2: GENERATE PURCHASE ORDER FROM AUDIO\n======================================================================\n\n======================================================================\nAUDIO TO PURCHASE_ORDER CONVERTER\n======================================================================\n\nSTEP 3: Extracting structured information...\nSTEP 4: Generating PURCHASE_ORDER...\n\nâœ… PURCHASE_ORDER generated and saved!\nğŸ“ File: /kaggle/working/purchase_order_Random recording for ReqGen.txt\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CUSTOM INSTRUCTION EXAMPLES FOR FLAN-T5\n# ============================================================================\n# ============================================================================\n\"\"\"\nğŸ’¡ CUSTOM INSTRUCTION IDEAS (for FLAN-T5):\n\nGeneral:\n- \"Summarize the main points\"\n- \"Provide a brief overview\"\n- \"Extract the key information\"\n\nBusiness:\n- \"Summarize the key business decisions and action items\"\n- \"List the main discussion points from this meeting\"\n- \"What are the important takeaways for stakeholders?\"\n\nEducational:\n- \"Summarize the main concepts taught in this lecture\"\n- \"What are the key learning objectives?\"\n- \"Provide a student-friendly summary\"\n\nTechnical:\n- \"Summarize the technical approach and methodology\"\n- \"What are the main technical challenges discussed?\"\n- \"Extract the implementation details\"\n\nNews/Media:\n- \"Summarize who, what, when, where, and why\"\n- \"What is the main story and its impact?\"\n- \"Provide a headline-style summary\"\n\"\"\"\n\n\n# ============================================================================\n# T5 MODEL QUICK REFERENCE\n# ============================================================================\n\n\"\"\"\nğŸ“š T5 MODEL GUIDE:\n\n1. t5-small (60M params)\n   - Fastest\n   - Good for short audio (<5 min)\n   - Lower quality\n   - Best for: Quick tests, resource-limited\n\n2. t5-base (220M params) â† RECOMMENDED\n   - Balanced speed/quality\n   - Works for any audio length\n   - Best general-purpose choice\n   - Best for: Most use cases\n\n3. t5-large (770M params)\n   - High quality\n   - Slower\n   - Requires more GPU memory\n   - Best for: Quality-critical tasks\n\n4. google/flan-t5-base (220M params) â† BEST FOR INSTRUCTIONS\n   - Instruction-tuned version\n   - Works with custom instructions\n   - Better understanding of context\n   - Best for: Specific summarization goals\n\n5. google/flan-t5-large (770M params)\n   - Best quality with instructions\n   - Excellent context understanding\n   - Slower, needs good GPU\n   - Best for: Professional applications\n\nâš¡ SPEED COMPARISON (relative):\nt5-small: 1x\nt5-base: 2.5x\nt5-large: 8x\nflan-t5-base: 2.5x\nflan-t5-large: 8x\n\nğŸ’¾ MEMORY USAGE:\nt5-small: ~300 MB\nt5-base: ~900 MB\nt5-large: ~3 GB\nflan-t5-base: ~900 MB\nflan-t5-large: ~3 GB\n\"\"\"","metadata":{"jupyter":{"source_hidden":true}}},{"cell_type":"markdown","source":"Summary to BRD / PO\n\nHow It Works\n\nAudio â†’ Transcription (Whisper)\nTranscription â†’ Summary (T5)\nSummary â†’ Structured Sections (NLP extraction)\nSections â†’ Formatted Document (Template formatting)\n\nThe formatter automatically extracts:\n\nRequirements (words: require, need, must, should)\nDecisions (words: decide, agreed, approved)\nAction Items (words: will, task, assign, responsible)\nTimeline (words: deadline, date, week, month)\nBudget (words: cost, budget, price, payment)\nRisks (words: risk, concern, issue, challenge)\nTechnical (words: technical, system, platform, API)\n\n Tips for Best Results\n\nUse comprehensive/detailed strategy for documents\nProvide metadata for professional formatting\nProcess once, save multiple formats:","metadata":{"jupyter":{"source_hidden":true}}},{"cell_type":"code","source":"# following code in markdown: Full audio to brd / po using above code, will take modules from this code and add it \n# to abv code and save it as version 3","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\"\"\" Smart T5 Large Audio to Professional Documents Converter\nUses: Whisper Large + FLAN-T5-Large\nOutputs: BRD, Purchase Order, and other business documents\nOptimized for Kaggle with GPU acceleration\n\"\"\"\n\nimport whisper\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport torch\nimport os\nimport re\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# INSTALLATION (Run in Kaggle first cell):\n# !pip install -q openai-whisper transformers sentencepiece accelerate\n# ============================================================================\n\n\nclass SmartT5LargeDocumentGenerator:\n    \"\"\"\n    Complete pipeline: Audio â†’ T5 Large Summary â†’ Professional Documents\n    Handles: BRD, Purchase Orders, Meeting Minutes, Technical Specs\n    \"\"\"\n    \n    def __init__(self, whisper_model=\"large\", t5_model=\"google/flan-t5-large\"):\n        \"\"\"\n        Initialize with LARGE models for highest quality\n        \n        Args:\n            whisper_model: 'large' for best transcription\n            t5_model: 'google/flan-t5-large' for best summarization\n        \"\"\"\n        \n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        \n        if self.device == \"cpu\":\n            print(\"âš ï¸  WARNING: Running on CPU will be VERY SLOW!\")\n            print(\"   Enable GPU in Kaggle: Settings â†’ Accelerator â†’ GPU T4 x2\\n\")\n        \n        print(f\"ğŸ”§ Device: {self.device}\")\n        if self.device == \"cuda\":\n            print(f\"ğŸš€ GPU: {torch.cuda.get_device_name(0)}\")\n            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n            print(f\"ğŸ’¾ GPU Memory: {gpu_memory:.2f} GB\")\n        \n        # Load Whisper Large\n        print(f\"\\nğŸ“¥ Loading Whisper Large...\")\n        self.whisper_model = whisper.load_model(whisper_model, device=self.device)\n        print(\"âœ… Whisper Large loaded!\")\n        \n        # Load FLAN-T5 Large\n        print(f\"\\nğŸ“¥ Loading FLAN-T5 Large...\")\n        self.tokenizer = T5Tokenizer.from_pretrained(t5_model, legacy=False)\n        \n        if self.device == \"cuda\":\n            self.model = T5ForConditionalGeneration.from_pretrained(\n                t5_model,\n                torch_dtype=torch.float16,\n                device_map=\"auto\"\n            )\n        else:\n            self.model = T5ForConditionalGeneration.from_pretrained(\n                t5_model,\n                torch_dtype=torch.float32\n            ).to(self.device)\n        \n        print(\"âœ… FLAN-T5 Large loaded!\")\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"âœ¨ Smart T5 Large Document Generator Ready!\")\n        print(\"=\"*70 + \"\\n\")\n    \n    def transcribe_audio(self, audio_path):\n        \"\"\"Transcribe audio with Whisper Large\"\"\"\n        \n        if not os.path.exists(audio_path):\n            raise FileNotFoundError(f\"âŒ File not found: {audio_path}\")\n        \n        file_size = os.path.getsize(audio_path) / (1024 * 1024)\n        print(f\"ğŸµ Audio: {os.path.basename(audio_path)} ({file_size:.2f} MB)\")\n        print(f\"â³ Transcribing with Whisper Large...\\n\")\n        \n        result = self.whisper_model.transcribe(\n            audio_path,\n            task='translate',\n            language=None,\n            fp16=self.device == \"cuda\",\n            verbose=False,\n            beam_size=5,\n            best_of=5,\n            temperature=0.0\n        )\n        \n        lang_map = {\n            'hi': 'Hindi (à¤¹à¤¿à¤¨à¥à¤¦à¥€)',\n            'en': 'English',\n            'mr': 'Marathi (à¤®à¤°à¤¾à¤ à¥€)'\n        }\n        \n        detected = result.get('language', 'unknown')\n        text = result['text'].strip()\n        word_count = len(text.split())\n        \n        print(f\"âœ… Transcription complete!\")\n        print(f\"ğŸŒ Language: {lang_map.get(detected, detected)}\")\n        print(f\"ğŸ“ Words: {word_count}\\n\")\n        \n        return {\n            'text': text,\n            'language': lang_map.get(detected, detected),\n            'word_count': word_count\n        }\n    \n    def generate_summary(self, text, custom_instruction=None, max_length=512):\n        \"\"\"Generate summary with FLAN-T5 Large\"\"\"\n        \n        print(f\"ğŸ“Š Generating high-quality summary with FLAN-T5 Large...\")\n        \n        # Prepare instruction\n        if custom_instruction:\n            input_text = f\"{custom_instruction}: {text}\"\n        else:\n            input_text = f\"Provide a comprehensive summary including key points, decisions, requirements, and action items: {text}\"\n        \n        # Tokenize\n        inputs = self.tokenizer(\n            input_text,\n            return_tensors=\"pt\",\n            max_length=512,\n            truncation=True,\n            padding=True\n        ).to(self.device)\n        \n        # Generate\n        with torch.no_grad():\n            summary_ids = self.model.generate(\n                inputs[\"input_ids\"],\n                max_length=max_length,\n                min_length=max_length // 4,\n                num_beams=8,\n                length_penalty=1.8,\n                early_stopping=True,\n                no_repeat_ngram_size=4,\n                repetition_penalty=1.3,\n                temperature=1.0,\n                do_sample=False\n            )\n        \n        summary = self.tokenizer.decode(\n            summary_ids[0],\n            skip_special_tokens=True,\n            clean_up_tokenization_spaces=True\n        )\n        \n        print(f\"âœ… Summary generated: {len(summary.split())} words\\n\")\n        \n        return summary\n    \n    def extract_structured_info(self, summary_text):\n        \"\"\"Extract structured information from summary\"\"\"\n        \n        info = {\n            'requirements': [],\n            'decisions': [],\n            'action_items': [],\n            'timeline': [],\n            'budget': [],\n            'risks': [],\n            'technical': [],\n            'deliverables': [],\n            'stakeholders': []\n        }\n        \n        sentences = re.split(r'[.!?]+', summary_text)\n        \n        for sentence in sentences:\n            sentence = sentence.strip()\n            if not sentence:\n                continue\n            \n            lower = sentence.lower()\n            \n            # Requirements\n            if any(w in lower for w in ['require', 'need', 'must', 'should', 'shall', 'expect']):\n                info['requirements'].append(sentence)\n            \n            # Decisions\n            if any(w in lower for w in ['decide', 'agreed', 'approved', 'confirmed', 'finalized']):\n                info['decisions'].append(sentence)\n            \n            # Action items\n            if any(w in lower for w in ['will', 'task', 'action', 'assign', 'responsible', 'owner']):\n                info['action_items'].append(sentence)\n            \n            # Timeline\n            if any(w in lower for w in ['deadline', 'timeline', 'date', 'week', 'month', 'schedule', 'due']):\n                info['timeline'].append(sentence)\n            \n            # Budget\n            if any(w in lower for w in ['cost', 'budget', 'price', 'payment', 'fund', 'expense', '$', 'rs', 'rupee', 'inr']):\n                info['budget'].append(sentence)\n            \n            # Risks\n            if any(w in lower for w in ['risk', 'concern', 'issue', 'challenge', 'problem', 'blocker']):\n                info['risks'].append(sentence)\n            \n            # Technical\n            if any(w in lower for w in ['technical', 'technology', 'system', 'platform', 'api', 'database', 'infrastructure']):\n                info['technical'].append(sentence)\n            \n            # Deliverables\n            if any(w in lower for w in ['deliver', 'output', 'product', 'feature', 'component', 'milestone']):\n                info['deliverables'].append(sentence)\n            \n            # Stakeholders\n            if any(w in lower for w in ['stakeholder', 'team', 'department', 'client', 'customer', 'vendor']):\n                info['stakeholders'].append(sentence)\n        \n        return info\n    \n    def generate_brd(self, summary_text, structured_info, metadata):\n        \"\"\"Generate Business Requirements Document\"\"\"\n        \n        doc = f\"\"\"\n{'='*80}\nBUSINESS REQUIREMENTS DOCUMENT (BRD)\n{'='*80}\n\nDocument Information:\n--------------------\nProject Name:     {metadata.get('project_name', 'Audio Extracted Project')}\nDocument Date:    {metadata.get('date', datetime.now().strftime('%Y-%m-%d'))}\nVersion:          {metadata.get('version', '1.0')}\nPrepared By:      {metadata.get('author', 'T5 Large Audio Analysis System')}\nStatus:           {metadata.get('status', 'Draft - Extracted from Audio')}\nDepartment:       {metadata.get('department', 'TBD')}\nSponsor:          {metadata.get('sponsor', 'TBD')}\n\n\n1. EXECUTIVE SUMMARY\n{'='*80}\n\n{summary_text}\n\n\n2. BUSINESS OBJECTIVES\n{'='*80}\n\nBased on the audio discussion, the key business objectives are:\n\n\"\"\"\n        \n        # Add objectives from summary\n        if structured_info['requirements']:\n            for idx, req in enumerate(structured_info['requirements'][:5], 1):\n                doc += f\"OBJ-{idx}: {req}\\n\"\n        else:\n            doc += \"Business objectives to be refined based on stakeholder review.\\n\"\n        \n        doc += f\"\"\"\n\n3. BUSINESS REQUIREMENTS\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['requirements']:\n            for idx, req in enumerate(structured_info['requirements'], 1):\n                doc += f\"BR-{idx:03d}: {req}\\n\"\n                doc += f\"         Priority: {metadata.get('priority', 'Medium')}\\n\"\n                doc += f\"         Status: New\\n\"\n                doc += f\"         Source: Audio Discussion\\n\\n\"\n        else:\n            doc += \"Business requirements extracted from executive summary above.\\n\"\n        \n        doc += f\"\"\"\n\n4. FUNCTIONAL REQUIREMENTS\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['technical']:\n            for idx, tech in enumerate(structured_info['technical'], 1):\n                doc += f\"FR-{idx:03d}: {tech}\\n\"\n                doc += f\"         Category: {metadata.get('category', 'Technical')}\\n\"\n                doc += f\"         Priority: {metadata.get('priority', 'Medium')}\\n\\n\"\n        else:\n            doc += \"Functional requirements to be detailed in technical specification.\\n\"\n        \n        doc += f\"\"\"\n\n5. STAKEHOLDERS\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['stakeholders']:\n            doc += \"Stakeholders identified in discussion:\\n\\n\"\n            for stakeholder in structured_info['stakeholders']:\n                doc += f\"â€¢ {stakeholder}\\n\"\n        else:\n            doc += f\"\"\"\nPrimary Stakeholders:\nâ€¢ Project Sponsor: {metadata.get('sponsor', 'TBD')}\nâ€¢ Business Owner: {metadata.get('business_owner', 'TBD')}\nâ€¢ Project Manager: {metadata.get('pm', 'TBD')}\nâ€¢ End Users: {metadata.get('end_users', 'As discussed in audio')}\n\"\"\"\n        \n        doc += f\"\"\"\n\n6. KEY DECISIONS\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['decisions']:\n            for idx, decision in enumerate(structured_info['decisions'], 1):\n                doc += f\"D{idx}. {decision}\\n\"\n                doc += f\"    Date: {metadata.get('date', 'TBD')}\\n\"\n                doc += f\"    Decision Maker: {metadata.get('decision_maker', 'TBD')}\\n\\n\"\n        else:\n            doc += \"Key decisions documented in executive summary.\\n\"\n        \n        doc += f\"\"\"\n\n7. SCOPE\n{'='*80}\n\nIn Scope:\n\"\"\"\n        \n        if structured_info['deliverables']:\n            for deliverable in structured_info['deliverables']:\n                doc += f\"â€¢ {deliverable}\\n\"\n        else:\n            doc += \"â€¢ As defined in requirements above\\n\"\n        \n        doc += \"\"\"\n\nOut of Scope:\nâ€¢ Items not mentioned in the audio discussion\nâ€¢ Features to be considered for future phases\n\n\"\"\"\n        \n        doc += f\"\"\"\n\n8. TIMELINE & MILESTONES\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['timeline']:\n            for milestone in structured_info['timeline']:\n                doc += f\"â€¢ {milestone}\\n\"\n        else:\n            doc += f\"\"\"\nProject Timeline:\nâ€¢ Requirements Phase: {metadata.get('req_phase', 'TBD')}\nâ€¢ Design Phase: {metadata.get('design_phase', 'TBD')}\nâ€¢ Development Phase: {metadata.get('dev_phase', 'TBD')}\nâ€¢ Testing Phase: {metadata.get('test_phase', 'TBD')}\nâ€¢ Deployment: {metadata.get('deployment', 'TBD')}\n\"\"\"\n        \n        doc += f\"\"\"\n\n9. BUDGET & RESOURCES\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['budget']:\n            for budget_item in structured_info['budget']:\n                doc += f\"â€¢ {budget_item}\\n\"\n        else:\n            doc += f\"\"\"\nEstimated Budget: {metadata.get('budget', 'To be determined')}\n\nResource Requirements:\nâ€¢ Team Size: {metadata.get('team_size', 'TBD')}\nâ€¢ Duration: {metadata.get('duration', 'TBD')}\nâ€¢ External Resources: {metadata.get('external_resources', 'TBD')}\n\"\"\"\n        \n        doc += f\"\"\"\n\n10. RISKS & ASSUMPTIONS\n{'='*80}\n\nRisks Identified:\n\"\"\"\n        \n        if structured_info['risks']:\n            for idx, risk in enumerate(structured_info['risks'], 1):\n                doc += f\"{idx}. {risk}\\n\"\n                doc += f\"   Impact: {metadata.get('risk_impact', 'Medium')}\\n\"\n                doc += f\"   Mitigation: To be defined\\n\\n\"\n        else:\n            doc += \"Risk assessment to be conducted during project planning.\\n\"\n        \n        doc += \"\"\"\n\nAssumptions:\nâ€¢ Resources will be available as per project timeline\nâ€¢ Stakeholder approvals will be obtained in timely manner\nâ€¢ Technical infrastructure is available and ready\n\n\"\"\"\n        \n        doc += f\"\"\"\n\n11. DEPENDENCIES\n{'='*80}\n\nâ€¢ Dependencies identified in audio discussion\nâ€¢ External systems and integrations as required\nâ€¢ Third-party services and vendors as needed\n\n\n12. SUCCESS CRITERIA\n{'='*80}\n\nThe project will be considered successful when:\n\nâ€¢ All business requirements are met\nâ€¢ System is deployed and operational\nâ€¢ User acceptance testing is completed successfully\nâ€¢ Stakeholders sign off on deliverables\n\n\n13. APPROVAL\n{'='*80}\n\nThis document has been reviewed and approved by:\n\n\nBusiness Owner: _____________________    Date: ___________\n\nSignature:      _____________________\n\n\nProject Sponsor: ____________________    Date: ___________\n\nSignature:       ____________________\n\n\n{'='*80}\nDocument Generated from Audio Analysis using Whisper Large + FLAN-T5 Large\nGenerated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n{'='*80}\n\"\"\"\n        \n        return doc\n    \n    def generate_purchase_order(self, summary_text, structured_info, metadata):\n        \"\"\"Generate Purchase Order\"\"\"\n        \n        doc = f\"\"\"\n{'='*80}\nPURCHASE ORDER\n{'='*80}\n\nPO Number:        {metadata.get('po_number', 'PO-' + datetime.now().strftime('%Y%m%d-%H%M'))}\nDate:             {metadata.get('date', datetime.now().strftime('%Y-%m-%d'))}\nStatus:           {metadata.get('status', 'Draft - Extracted from Audio')}\n\n\nVENDOR INFORMATION:\n{'='*80}\nVendor Name:      {metadata.get('vendor_name', 'TBD - As per audio discussion')}\nVendor Code:      {metadata.get('vendor_code', 'TBD')}\nAddress:          {metadata.get('vendor_address', 'TBD')}\nCity/State/ZIP:   {metadata.get('vendor_location', 'TBD')}\nContact Person:   {metadata.get('vendor_contact', 'TBD')}\nPhone:            {metadata.get('vendor_phone', 'TBD')}\nEmail:            {metadata.get('vendor_email', 'TBD')}\nGST/Tax ID:       {metadata.get('vendor_gst', 'TBD')}\n\n\nBUYER INFORMATION:\n{'='*80}\nCompany Name:     {metadata.get('company_name', 'Your Company Ltd.')}\nDepartment:       {metadata.get('department', 'Procurement')}\nAddress:          {metadata.get('buyer_address', 'TBD')}\nCity/State/ZIP:   {metadata.get('buyer_location', 'TBD')}\nContact Person:   {metadata.get('buyer_contact', metadata.get('author', 'TBD'))}\nPhone:            {metadata.get('buyer_phone', 'TBD')}\nEmail:            {metadata.get('buyer_email', 'TBD')}\n\n\nPURCHASE ORDER SUMMARY:\n{'='*80}\n\nBased on Audio Discussion:\n{summary_text}\n\n\nDETAILED LINE ITEMS:\n{'='*80}\n\n\"\"\"\n        \n        # Extract items from deliverables or requirements\n        items = structured_info['deliverables'] if structured_info['deliverables'] else structured_info['requirements']\n        \n        doc += f\"{'Item':<5} {'Description':<45} {'Qty':<8} {'Unit':<10} {'Price':<12} {'Total':<12}\\n\"\n        doc += \"-\" * 100 + \"\\n\"\n        \n        if items:\n            for idx, item in enumerate(items[:15], 1):  # Max 15 items\n                clean_item = item.replace('\\n', ' ')[:42]\n                doc += f\"{idx:<5} {clean_item:<45} {'TBD':<8} {'Each':<10} {'TBD':<12} {'TBD':<12}\\n\"\n        else:\n            doc += f\"{'1':<5} {'Items/Services as per audio discussion':<45} {'TBD':<8} {'Each':<10} {'TBD':<12} {'TBD':<12}\\n\"\n        \n        doc += \"\\n\"\n        \n        doc += f\"\"\"\n\nCOST BREAKDOWN:\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['budget']:\n            doc += \"Cost Details (from audio discussion):\\n\\n\"\n            for budget_item in structured_info['budget']:\n                doc += f\"â€¢ {budget_item}\\n\"\n            doc += \"\\n\"\n        \n        doc += f\"\"\"\nSubtotal:                                                    {metadata.get('subtotal', 'TBD')}\nDiscount (if any):                                           {metadata.get('discount', '0.00')}\n                                                             ___________\nSubtotal after Discount:                                     {metadata.get('subtotal_after_discount', 'TBD')}\n\nTax/GST ({metadata.get('tax_rate', '18')}%):                                             {metadata.get('tax_amount', 'TBD')}\nShipping & Handling:                                         {metadata.get('shipping', 'TBD')}\nOther Charges:                                               {metadata.get('other_charges', '0.00')}\n                                                             ___________\nTOTAL AMOUNT:                                                {metadata.get('total_amount', 'TBD')}\n                                                             ===========\n\n\nTERMS & CONDITIONS:\n{'='*80}\n\nPayment Terms:         {metadata.get('payment_terms', 'Net 30 Days')}\nDelivery Terms:        {metadata.get('delivery_terms', 'FOB Destination')}\nExpected Delivery:     {metadata.get('delivery_date', 'TBD - As per discussion')}\nDelivery Address:      {metadata.get('delivery_address', 'As per buyer information above')}\nShipping Method:       {metadata.get('shipping_method', 'Standard')}\nWarranty:              {metadata.get('warranty', 'As per vendor terms')}\nReturn Policy:         {metadata.get('return_policy', 'As per vendor terms')}\n\n\nPAYMENT SCHEDULE:\n{'='*80}\n\n\"\"\"\n        \n        if metadata.get('payment_schedule'):\n            doc += metadata['payment_schedule']\n        else:\n            doc += f\"\"\"\nâ€¢ Advance Payment: {metadata.get('advance_payment', '0%')} on PO confirmation\nâ€¢ Balance Payment: {metadata.get('balance_payment', '100%')} {metadata.get('payment_terms', 'Net 30')}\n\"\"\"\n        \n        doc += f\"\"\"\n\nSPECIAL INSTRUCTIONS:\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['requirements']:\n            doc += \"Requirements from audio discussion:\\n\\n\"\n            for req in structured_info['requirements'][:5]:\n                doc += f\"â€¢ {req}\\n\"\n        else:\n            doc += \"As per audio discussion and mutual agreement.\\n\"\n        \n        doc += f\"\"\"\n\nADDITIONAL NOTES:\n{'='*80}\n\n\"\"\"\n        \n        if structured_info['action_items']:\n            doc += \"Action Items:\\n\\n\"\n            for action in structured_info['action_items'][:5]:\n                doc += f\"â€¢ {action}\\n\"\n        \n        doc += f\"\"\"\n\nVALIDITY:\n{'='*80}\n\nThis Purchase Order is valid until: {metadata.get('validity_date', 'TBD')}\n\n\nAPPROVAL & AUTHORIZATION:\n{'='*80}\n\nRequested By:\n\nName:      {metadata.get('requested_by', 'TBD')}\nTitle:     {metadata.get('requested_title', 'TBD')}\nDate:      {metadata.get('date', 'TBD')}\nSignature: _____________________\n\n\nApproved By:\n\nName:      {metadata.get('approved_by', 'TBD')}\nTitle:     {metadata.get('approved_title', 'Manager/Director')}\nDate:      ___________\nSignature: _____________________\n\n\nFinance Approval:\n\nName:      {metadata.get('finance_approval', 'TBD')}\nTitle:     Finance Manager\nDate:      ___________\nSignature: _____________________\n\n\nVENDOR ACCEPTANCE:\n{'='*80}\n\nWe accept the terms and conditions of this Purchase Order:\n\nVendor Name:    {metadata.get('vendor_name', 'TBD')}\nAuthorized By:  _____________________\nTitle:          _____________________\nDate:           ___________\nSignature:      _____________________\nCompany Seal:   \n\n\n{'='*80}\nPurchase Order Generated from Audio Analysis\nSystem: Whisper Large + FLAN-T5 Large\nGenerated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n{'='*80}\n\nIMPORTANT NOTES:\n- This is a preliminary document extracted from audio discussion\n- Please review and verify all details before finalization\n- TBD items must be filled in before final approval\n- Consult legal/procurement team for compliance review\n\"\"\"\n        \n        return doc\n    \n    def process_audio_to_document(\n        self,\n        audio_path,\n        document_type='brd',\n        custom_instruction=None,\n        metadata=None\n    ):\n        \"\"\"\n        Complete pipeline: Audio â†’ Summary â†’ Document\n        \n        Args:\n            audio_path: Path to audio file\n            document_type: 'brd' or 'purchase_order'\n            custom_instruction: Custom instruction for T5\n            metadata: Document metadata\n        \n        Returns:\n            dict with transcription, summary, and formatted document\n        \"\"\"\n        \n        print(\"=\"*70)\n        print(f\"AUDIO TO {document_type.upper()} CONVERTER\")\n        print(\"=\"*70 + \"\\n\")\n        \n        # Step 1: Transcribe\n        print(\"STEP 1: Transcribing with Whisper Large...\")\n        transcription = self.transcribe_audio(audio_path)\n        \n        # Step 2: Generate Summary\n        print(\"STEP 2: Generating summary with FLAN-T5 Large...\")\n        summary = self.generate_summary(\n            transcription['text'],\n            custom_instruction=custom_instruction\n        )\n        \n        # Step 3: Extract structured information\n        print(\"STEP 3: Extracting structured information...\")\n        structured_info = self.extract_structured_info(summary)\n        \n        # Step 4: Generate document\n        print(f\"STEP 4: Generating {document_type.upper()}...\\n\")\n        \n        if metadata is None:\n            metadata = {}\n        \n        metadata.setdefault('project_name', os.path.basename(audio_path).split('.')[0])\n        metadata.setdefault('date', datetime.now().strftime('%Y-%m-%d'))\n        \n        if document_type == 'brd':\n            formatted_doc = self.generate_brd(summary, structured_info, metadata)\n        elif document_type == 'purchase_order':\n            formatted_doc = self.generate_purchase_order(summary, structured_info, metadata)\n        else:\n            raise ValueError(f\"Unknown document type: {document_type}\")\n        \n        # Step 5: Save\n        output_filename = f\"/kaggle/working/{document_type}_{metadata['project_name']}.txt\"\n        with open(output_filename, 'w', encoding='utf-8') as f:\n            f.write(formatted_doc)\n        \n        print(f\"âœ… {document_type.upper()} generated and saved!\")\n        print(f\"ğŸ“ File: {output_filename}\\n\")\n        \n        return {\n            'transcription': transcription['text'],\n            'summary': summary,\n            'structured_info': structured_info,\n            'formatted_document': formatted_doc,\n            'output_file': output_filename\n        }\n\n\n# ============================================================================\n# USAGE EXAMPLES\n# ============================================================================\n\nif __name__ == \"__main__\":\n    \n    # ========================================================================\n    # STEP 1: Load Models ONCE\n    # ========================================================================\n    \n    print(\"=\"*70)\n    print(\"INITIALIZING T5 LARGE DOCUMENT GENERATOR\")\n    print(\"=\"*70 + \"\\n\")\n    \n    generator = SmartT5LargeDocumentGenerator(\n        whisper_model=\"large\",\n        t5_model=\"google/flan-t5-large\"\n    )\n    \n    \n    # ========================================================================\n    # EXAMPLE 1: Generate BRD from Audio\n    # ========================================================================\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"EXAMPLE 1: GENERATE BRD FROM AUDIO\")\n    print(\"=\"*70 + \"\\n\")\n    \n    brd_results = generator.process_audio_to_document(\n        audio_path=\"/kaggle/input/audio/requirements_meeting.mp3\",\n        document_type='brd',\n        custom_instruction=\"Extract all business requirements, decisions, timeline, and stakeholder information\",\n        metadata={\n            'project_name': 'Mobile_App_Redesign',\n            'version': '1.0',\n            'status': 'Draft',\n            'author': 'Business Analysis Team',\n            'department': 'Product Development',\n            'sponsor': 'VP of Product',\n            'priority': 'High'\n        }\n    )\n    \n    print(\"BRD Summary Preview:\")\n    print(brd_results['summary'][:300] + \"...\\n\")\n    \n    \n    # ========================================================================\n    # EXAMPLE 2: Generate Purchase Order from Audio\n    # ========================================================================\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"EXAMPLE 2: GENERATE PURCHASE ORDER FROM AUDIO\")\n    print(\"=\"*70 + \"\\n\")\n    \n    po_results = generator.process_audio_to_document(\n        audio_path=\"/kaggle/input/audio/vendor_discussion.mp3\",\n        document_type='purchase_order',\n        custom_instruction=\"Extract vendor details, items to be purchased, quantities, costs, and delivery terms\",\n        metadata={\n            'po_number': 'PO-2024-001',\n            'vendor_name': 'ABC Technology Solutions Pvt Ltd',\n            'vendor_address': '123 Tech Park, Bangalore',\n            'vendor_contact': 'Mr. Rajesh Kumar',\n            'vendor_phone': '+91 98765 43210',\n            'vendor_email': 'rajesh@abctech.com',\n            'vendor_gst': '29ABCDE1234F1Z5',\n            'company_name': 'XYZ Enterprises Ltd',\n            'department': 'IT Procurement',\n            'payment_terms': 'Net 30 Days',\n            'delivery_date': '2024-02-15',\n            'shipping_method': 'Express Delivery',\n            'tax_rate': '18'\n        }\n    )\n    \n    print(\"PO Summary Preview:\")\n    print(po_results['summary'][:300] + \"...\\n\")\n    \n    \n    # ========================================================================\n    # EXAMPLE 3: Process Multiple Audio Files\n    # ========================================================================\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"EXAMPLE 3: BATCH PROCESSING\")\n    print(\"=\"*70 + \"\\n\")\n    \n    audio_documents = [\n        {\n            'path': '/kaggle/input/audio/meeting1.mp3',\n            'type': 'brd',\n            'metadata': {'project_name': 'Project_Alpha', 'version': '1.0'}\n        },\n        {\n            'path': '/kaggle/input/audio/vendor_call.mp3',\n            'type': 'purchase_order',\n            'metadata': {'vendor_name': 'Vendor XYZ', 'po_number': 'PO-2024-002'}\n        }\n    ]\n    \n    all_results = []\n    \n    for item in audio_documents:\n        print(f\"\\nProcessing: {item['path']}\")\n        \n        try:\n            results = generator.process_audio_to_document(\n                audio_path=item['path'],\n                document_type=item['type'],\n                metadata=item['metadata']\n            )\n            all_results.append(results)\n            print(f\"âœ… Generated {item['type'].upper()}\\n\")\n        except Exception as e:\n            print(f\"âŒ Error: {str(e)}\\n\")\n            continue\n    \n    print(f\"âœ… Batch processing complete! Generated {len(all_results)} documents.\")\n\n\n# ============================================================================\n# COMPLETE WORKFLOW EXAMPLE\n# ============================================================================\n\n\"\"\"\nCOMPLETE WORKFLOW:\n\n# Cell 1: Installation\n!pip install -q openai-whisper transformers sentencepiece accelerate\n\n# Cell 2: Paste entire code above\n\n# Cell 3: Load models ONCE\ngenerator = SmartT5LargeDocumentGenerator(\n    whisper_model=\"large\",\n    t5_model=\"google/flan-t5-large\"\n)\n\n# Cell 4: Generate BRD\nbrd = generator.process_audio_to","metadata":{"jupyter":{"source_hidden":true}}}]}