{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "Kaggle notebooks run on a Linux-based virtual machine in the cloud, and they handle system-level dependencies differently.\n",
    "How to use Audio Libraries in Kaggle\n",
    "Kaggle environments come pre-configured with most standard data science libraries (like NumPy and SciPy). You only need to ensure the Python audio interface libraries are installed in the notebook session.\n",
    "Here are the exact steps to get microphone access working in a Kaggle notebook:\n",
    "1. Install Required Libraries via Notebook Command\n",
    "Kaggle often has these pre-installed, but running the command guarantees they are available in your session:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ö†Ô∏è Important Constraints\n",
    "The BART summarization model has these limits:\n",
    "\n",
    "Minimum: ~30 words (won't work well below this)\n",
    "Maximum: ~500 words per summary\n",
    "Recommended range: 50-300 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q openai-whisper\n",
    "!pip install -q transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T12:13:54.513658Z",
     "iopub.status.busy": "2025-12-03T12:13:54.513360Z",
     "iopub.status.idle": "2025-12-03T12:14:46.008573Z",
     "shell.execute_reply": "2025-12-03T12:14:46.007876Z",
     "shell.execute_reply.started": "2025-12-03T12:13:54.513615Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 12:13:58.373261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764764038.394871     326 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764764038.401302     326 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Loading Whisper 'medium' model...\n",
      "‚úÖ Whisper loaded!\n",
      "\n",
      "üì• Loading BART summarization model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ BART loaded!\n",
      "\n",
      "============================================================\n",
      "‚ú® Ready to process audio files!\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "üéØ KAGGLE AUDIO SUMMARIZER (ADAPTIVE)\n",
      "============================================================\n",
      "\n",
      "üéµ Audio file: Japanese parenting style.m4a\n",
      "üì¶ Size: 1.92 MB\n",
      "‚è≥ Transcribing... (this may take several minutes)\n",
      "\n",
      "Detected language: English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23675/23675 [00:23<00:00, 1000.63frames/s]\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transcription complete!\n",
      "üåç Detected: English\n",
      "üìù Length: 3199 characters\n",
      "\n",
      "üìä Adaptive summary: 250 words (from 501 words)\n",
      "\n",
      "üìä Generating summary...\n",
      "üìè Input: 501 words ‚Üí Target summary: 250 words\n",
      "üìÑ Processing 1 chunk(s)...\n",
      "  ‚û§ Chunk 1/1 (501 words ‚Üí 250 words)... ‚úì\n",
      "‚úÖ Summary ready!\n",
      "\n",
      "============================================================\n",
      "üìã RESULTS\n",
      "============================================================\n",
      "üìÅ File: Japanese parenting style.m4a\n",
      "üåç Language: English\n",
      "üìè Original: 501 words\n",
      "üìè Summary: 74 words\n",
      "üìâ Compression: 85.2%\n",
      "\n",
      "============================================================\n",
      "‚ú® SUMMARY (English):\n",
      "============================================================\n",
      "Japanese obedience starts with emotional safety, not discipline. Before asking children to listen, the parents build an unshakable bond. Children who feel deeply secure do not fight for attention. They already have it. And children who feel safe listen faster. Japanese parents avoid power struggles altogether. They repeat expectations calmly, without changing the boundary. Natural consequences replace punishment. Children mirror the emotional climate they grew up in. The power of WE makes listening natural.\n",
      "\n",
      "============================================================\n",
      "üìÑ FULL TRANSCRIPTION (First 1000 chars):\n",
      "============================================================\n",
      "Japan raises some of the most respectful kids on earth but not through strict rules. The secret is AMEI, a parenting strategy that builds such deep emotional security that children obey out of connection, not fear. Here is how this creates kids who listen the first time. AMEI creates a bond that makes obedience natural. It means letting a child depend on you fully in the early years. A secure child does not fight for attention, they already feel seen. And kids who feel seen listen more willingly. Japanese obedience starts with emotional safety, not discipline. Before asking children to listen, the parents build an unshakable bond. Kids who feel deeply secure do not fight for attention. They already have it. And children who feel safe listen faster. Closeness comes before discipline in Japan. Mothers stay physically near their toddlers throughout the day. They respond quickly to needs, they nurture connection through touch, tone and attention. When trust is strong, cooperation becomes e...\n",
      "============================================================\n",
      "\n",
      "üíæ Saved to: /kaggle/working/audio_summary.txt\n",
      "üì• Download from Kaggle Output section\n",
      "\n",
      "\n",
      "üéØ Summary:\n",
      "Japanese obedience starts with emotional safety, not discipline. Before asking children to listen, the parents build an unshakable bond. Children who feel deeply secure do not fight for attention. They already have it. And children who feel safe listen faster. Japanese parents avoid power struggles altogether. They repeat expectations calmly, without changing the boundary. Natural consequences replace punishment. Children mirror the emotional climate they grew up in. The power of WE makes listening natural.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multilingual Audio Transcription & Summarization for KAGGLE NOTEBOOK\n",
    "Supports: Hindi, English, Marathi (and 90+ languages)\n",
    "Optimized for Kaggle environment with GPU support\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: INSTALL REQUIRED PACKAGES (Run this cell first in Kaggle)\n",
    "# ============================================================================\n",
    "\n",
    "# Uncomment and run these in a Kaggle notebook cell:\n",
    "# !pip install -q openai-whisper\n",
    "# !pip install -q git+https://github.com/openai/whisper.git\n",
    "# !pip install -q transformers\n",
    "# !pip install -q accelerate\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: IMPORT LIBRARIES\n",
    "# ============================================================================\n",
    "\n",
    "import whisper\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: KAGGLE-OPTIMIZED AUDIO SUMMARIZER CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class KaggleAudioSummarizer:\n",
    "    def __init__(self, whisper_model=\"medium\"):\n",
    "        \"\"\"\n",
    "        Initialize for Kaggle environment\n",
    "        \n",
    "        Args:\n",
    "            whisper_model: 'tiny', 'base', 'small', 'medium', 'large'\n",
    "                          For Kaggle: 'base' or 'medium' recommended\n",
    "        \"\"\"\n",
    "        # Check GPU availability\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        #print(f\"üîß Device: {self.device}\")\n",
    "        \n",
    "        #if self.device == \"cuda\":\n",
    "            #print(f\"üöÄ GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
    "            #print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        \n",
    "        # Load Whisper model\n",
    "        print(f\"\\nüì• Loading Whisper '{whisper_model}' model...\")\n",
    "        self.whisper_model = whisper.load_model(whisper_model, device=self.device)\n",
    "        print(\"‚úÖ Whisper loaded!\")\n",
    "        \n",
    "        # Load summarization model\n",
    "        print(\"\\nüì• Loading BART summarization model...\")\n",
    "        self.summarizer = pipeline(\n",
    "            \"summarization\",\n",
    "            model=\"facebook/bart-large-cnn\",\n",
    "            device=0 if self.device == \"cuda\" else -1,\n",
    "            torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
    "            framework=\"pt\",\n",
    "            truncation=True\n",
    "        )\n",
    "        print(\"‚úÖ BART loaded!\")\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚ú® Ready to process audio files!\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    def transcribe_audio(self, audio_path):\n",
    "        \"\"\"\n",
    "        Transcribe audio and translate to English\n",
    "        \n",
    "        Args:\n",
    "            audio_path: Path to audio file in Kaggle\n",
    "                       e.g., '/kaggle/input/your-dataset/audio.mp3'\n",
    "        \"\"\"\n",
    "        if not os.path.exists(audio_path):\n",
    "            raise FileNotFoundError(f\"‚ùå File not found: {audio_path}\")\n",
    "        \n",
    "        file_size = os.path.getsize(audio_path) / (1024 * 1024)  # MB\n",
    "        print(f\"üéµ Audio file: {os.path.basename(audio_path)}\")\n",
    "        print(f\"üì¶ Size: {file_size:.2f} MB\")\n",
    "        print(f\"‚è≥ Transcribing... (this may take several minutes)\\n\")\n",
    "        \n",
    "        # Transcribe with auto-translate to English\n",
    "        result = self.whisper_model.transcribe(\n",
    "            audio_path,\n",
    "            task='translate',  # Auto-translate to English\n",
    "            language=None,     # Auto-detect language\n",
    "            fp16=self.device == \"cuda\",  # Use FP16 on GPU\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        detected_lang = result.get('language', 'unknown')\n",
    "        lang_map = {\n",
    "            'hi': 'Hindi (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)',\n",
    "            'en': 'English',\n",
    "            'mr': 'Marathi (‡§Æ‡§∞‡§æ‡§†‡•Ä)',\n",
    "            'unknown': 'Unknown'\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Transcription complete!\")\n",
    "        print(f\"üåç Detected: {lang_map.get(detected_lang, detected_lang)}\")\n",
    "        print(f\"üìù Length: {len(result['text'])} characters\\n\")\n",
    "        #print(f\"üìù Details: {(result)} \\n\")\n",
    "        \n",
    "        return {\n",
    "            'text': result['text'].strip(),\n",
    "            'language': detected_lang,\n",
    "            'language_name': lang_map.get(detected_lang, detected_lang)\n",
    "        }\n",
    "    \n",
    "    def summarize_text(self, text, max_length=250, min_length=80):\n",
    "        \"\"\"\n",
    "        Generate summary from transcribed text with smart length handling\n",
    "        \"\"\"\n",
    "        print(\"üìä Generating summary...\")\n",
    "    \n",
    "        word_count = len(text.split())\n",
    "    \n",
    "    # If text is too short, return as-is\n",
    "        # if word_count < 50:\n",
    "        #     print(f\"‚ö†Ô∏è Text too short ({word_count} words). Returning original text.\")\n",
    "        #     return text\n",
    "    \n",
    "    # Adjust max_length based on input length\n",
    "    # Summary should be 30-50% of original length\n",
    "        adjusted_max_length = min(max_length, int(word_count * 0.6))\n",
    "        adjusted_min_length = min(min_length, int(word_count * 0.2))\n",
    "    \n",
    "    # Ensure min < max\n",
    "        if adjusted_min_length >= adjusted_max_length:\n",
    "            adjusted_min_length = max(10, adjusted_max_length - 20)\n",
    "    \n",
    "        print(f\"üìè Input: {word_count} words ‚Üí Target summary: {adjusted_max_length} words\")\n",
    "    \n",
    "    # Split into chunks (BART limit: ~1024 tokens ‚âà 800 words)\n",
    "        chunk_size = 800  # words\n",
    "        words = text.split()\n",
    "        chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    \n",
    "        print(f\"üìÑ Processing {len(chunks)} chunk(s)...\")\n",
    "    \n",
    "        summaries = []\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            chunk_word_count = len(chunk.split())\n",
    "        \n",
    "            if chunk_word_count < 50:\n",
    "                summaries.append(chunk)  # Too short to summarize\n",
    "                continue\n",
    "        \n",
    "        # Adjust length for this specific chunk\n",
    "            chunk_max = min(adjusted_max_length, int(chunk_word_count * 0.6))\n",
    "            chunk_min = min(adjusted_min_length, int(chunk_word_count * 0.3))\n",
    "        \n",
    "        # Ensure valid range\n",
    "            if chunk_min >= chunk_max:\n",
    "                chunk_min = max(10, chunk_max - 20)\n",
    "        \n",
    "            print(f\"  ‚û§ Chunk {idx+1}/{len(chunks)} ({chunk_word_count} words ‚Üí {chunk_max} words)...\", end=\" \")\n",
    "        # abv line is diff in the structured code check this if any chnges u need\n",
    "            try:\n",
    "                summary = self.summarizer(\n",
    "                    chunk,\n",
    "                    max_length=chunk_max,\n",
    "                    min_length=chunk_min,\n",
    "                    do_sample=False,\n",
    "                    truncation=True\n",
    "                )\n",
    "                summaries.append(summary[0]['summary_text'])\n",
    "                print(\"‚úì\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó (Error: {str(e)[:30]})\")\n",
    "                summaries.append(chunk[:500])  # Fallback: use first 500 chars\n",
    "                continue  # this summaries wala block is aalso diff in structrd code\n",
    "    \n",
    "        if not summaries:\n",
    "            return text\n",
    "    \n",
    "        combined = ' '.join(summaries)\n",
    "        combined_word_count = len(combined.split())\n",
    "    \n",
    "    # Final summary if still too long\n",
    "        if len(chunks) > 1 and combined_word_count > adjusted_max_length:\n",
    "            print(f\"  ‚û§ Final summary ({combined_word_count} words ‚Üí {adjusted_max_length} words)...\", end=\" \")\n",
    "        \n",
    "            final_max = min(adjusted_max_length, int(combined_word_count * 0.7))\n",
    "            final_min = min(adjusted_min_length, int(combined_word_count * 0.3))\n",
    "        \n",
    "            if final_min >= final_max:\n",
    "                final_min = max(10, final_max - 20)\n",
    "        \n",
    "            try:\n",
    "                final = self.summarizer(\n",
    "                    combined,\n",
    "                    max_length=final_max,\n",
    "                    min_length=final_min,\n",
    "                    do_sample=False,\n",
    "                    truncation=True\n",
    "                )\n",
    "                combined = final[0]['summary_text']\n",
    "                print(\"‚úì\")\n",
    "            except:\n",
    "                print(\"‚úó\")\n",
    "    \n",
    "        print(\"‚úÖ Summary ready!\\n\")\n",
    "        return combined\n",
    "    \n",
    "    def process_audio_adaptive(self, audio_path, summary_ratio=0.5, save_output=True):\n",
    "        \"\"\"\n",
    "        Process audio with adaptive summary length\n",
    "    \n",
    "        Args:\n",
    "        audio_path: Path to audio file\n",
    "        summary_ratio: Summary length as ratio of original (0.25 = 25%)\n",
    "        save_output: Save results\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üéØ KAGGLE AUDIO SUMMARIZER (ADAPTIVE)\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Transcribe\n",
    "        transcription = self.transcribe_audio(audio_path)\n",
    "        word_count = len(transcription['text'].split())\n",
    "    \n",
    "    # Calculate adaptive summary length\n",
    "        summary_length = max(50, int(word_count * summary_ratio))  # Min 50 words\n",
    "        summary_length = min(summary_length, 500)  # Max 500 words\n",
    "    \n",
    "        print(f\"üìä Adaptive summary: {summary_length} words (from {word_count} words)\\n\")\n",
    "    \n",
    "    # Summarize\n",
    "        summary = self.summarize_text(\n",
    "            transcription['text'],\n",
    "            max_length=summary_length,\n",
    "            min_length=summary_length // 3\n",
    "        )\n",
    "    \n",
    "        results = {\n",
    "            'audio_file': os.path.basename(audio_path),\n",
    "            'language': transcription['language_name'],\n",
    "            'transcription': transcription['text'],\n",
    "            'summary': summary,\n",
    "            'transcription_word_count': word_count,\n",
    "            'summary_word_count': len(summary.split())\n",
    "        }\n",
    "    \n",
    "        self._display_results(results)\n",
    "    \n",
    "        if save_output:\n",
    "            self._save_results(results)\n",
    "    \n",
    "        return results\n",
    "\n",
    "#################### \n",
    "#smart way to get summary length less than the transcription word count.\n",
    "\n",
    "#def smart_summary_length(word_count):\n",
    "#    \"\"\"Calculate optimal summary length based on original\"\"\"\n",
    "#    if word_count < 100:\n",
    "#        return word_count  # Too short to summarize\n",
    "#    elif word_count < 500:\n",
    "#        return int(word_count * 0.5)  # 50%\n",
    "#    elif word_count < 2000:\n",
    "#        return int(word_count * 0.3)  # 30%\n",
    " #   elif word_count < 5000:\n",
    " #       return int(word_count * 0.2)  # 20%\n",
    "  #  else:\n",
    "  #      return min(int(word_count * 0.15), 500)  # 15%, max 500\n",
    "\n",
    "# Use it:\n",
    "#transcription = summarizer.transcribe_audio(audio_file)\n",
    "#word_count = len(transcription['text'].split())\n",
    "#summary_length = smart_summary_length(word_count)\n",
    "\n",
    "#summary = summarizer.summarize_text(\n",
    "#    transcription['text'],\n",
    "#    max_length=summary_length\n",
    "#)\n",
    "\n",
    "###################\n",
    "   \n",
    "    \n",
    "    def _display_results(self, results):\n",
    "        \"\"\"Display results in notebook\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"üìã RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üìÅ File: {results['audio_file']}\")\n",
    "        print(f\"üåç Language: {results['language']}\")\n",
    "        print(f\"üìè Original: {results['transcription_word_count']} words\")\n",
    "        print(f\"üìè Summary: {results['summary_word_count']} words\")\n",
    "        print(f\"üìâ Compression: {100 * (1 - results['summary_word_count']/results['transcription_word_count']):.1f}%\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚ú® SUMMARY (English):\")\n",
    "        print(\"=\"*60)\n",
    "        print(results['summary'])\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìÑ FULL TRANSCRIPTION (First 1000 chars):\")\n",
    "        print(\"=\"*60)\n",
    "        print(results['transcription'][:1000] + \"...\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    def _save_results(self, results):\n",
    "        \"\"\"Save to Kaggle working directory (/kaggle/working/)\"\"\"\n",
    "        output_file = \"/kaggle/working/audio_summary.txt\"\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(\"KAGGLE AUDIO SUMMARY REPORT\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\\n\")\n",
    "            f.write(f\"Audio File: {results['audio_file']}\\n\")\n",
    "            f.write(f\"Detected Language: {results['language']}\\n\")\n",
    "            f.write(f\"Original Length: {results['transcription_word_count']} words\\n\")\n",
    "            f.write(f\"Summary Length: {results['summary_word_count']} words\\n\")\n",
    "            f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "            f.write(\"SUMMARY (English):\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\\n\")\n",
    "            f.write(results['summary'] + \"\\n\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(\"FULL TRANSCRIPTION (English):\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\\n\")\n",
    "            f.write(results['transcription'] + \"\\n\")\n",
    "        \n",
    "        print(f\"üíæ Saved to: {output_file}\")\n",
    "        print(\"üì• Download from Kaggle Output section\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE IN KAGGLE NOTEBOOK\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize the summarizer (run once)\n",
    "summarizer = KaggleAudioSummarizer(\n",
    "    whisper_model=\"large\"  # Options: 'tiny', 'base', 'small', 'medium', 'large'\n",
    ")\n",
    "\n",
    "# Process your audio file\n",
    "# Replace with your actual path from Kaggle Input\n",
    "audio_file = \"/kaggle/input/eng-hinbi-marathi-mix-audio/Japanese parenting style.m4a\"\n",
    "\n",
    "# Run the summarization\n",
    "results = summarizer.process_audio_adaptive(\n",
    "    audio_path=audio_file,\n",
    "    save_output=True        # Save to /kaggle/working/\n",
    "    #summary_length=500       # Adjust summary length\n",
    ")\n",
    "\n",
    "# Access individual results\n",
    "print(f\"\\nüéØ Summary:\\n{results['summary']}\\n\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE: PROCESS MULTIPLE FILES\n",
    "# ============================================================================\n",
    "\n",
    "def process_multiple_files(audio_folder):\n",
    "    \"\"\"Process all audio files in a Kaggle input folder\"\"\"\n",
    "    \n",
    "    import glob\n",
    "    \n",
    "    # Find all audio files\n",
    "    audio_files = glob.glob(f\"{audio_folder}/*.mp3\") + \\\n",
    "                  glob.glob(f\"{audio_folder}/*.wav\") + \\\n",
    "                  glob.glob(f\"{audio_folder}/*.m4a\")\n",
    "    \n",
    "    print(f\"Found {len(audio_files)} audio file(s)\\n\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for audio in audio_files:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {os.path.basename(audio)}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        try:\n",
    "            results = summarizer.process_audio(audio, save_output=False)\n",
    "            all_results.append(results)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\\n\")\n",
    "            continue\n",
    "    \n",
    "    # Save combined results\n",
    "    with open(\"/kaggle/working/all_summaries.txt\", 'w', encoding='utf-8') as f:\n",
    "        for r in all_results:\n",
    "            f.write(f\"\\n{'='*60}\\n\")\n",
    "            f.write(f\"File: {r['audio_file']}\\n\")\n",
    "            f.write(f\"Language: {r['language']}\\n\")\n",
    "            f.write(f\"{'='*60}\\n\")\n",
    "            f.write(f\"SUMMARY:\\n{r['summary']}\\n\\n\\n\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Processed {len(all_results)} files\")\n",
    "    print(f\"üíæ Combined summaries saved to /kaggle/working/all_summaries.txt \\n\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Example usage:\n",
    "# results = process_multiple_files(\"/kaggle/input/your-dataset-name\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# QUICK START GUIDE FOR KAGGLE\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "üöÄ QUICK START IN KAGGLE:\n",
    "\n",
    "1. CREATE NEW NOTEBOOK\n",
    "   - Go to kaggle.com\n",
    "   - Create new notebook\n",
    "   - Enable GPU (Settings ‚Üí Accelerator ‚Üí GPU T4 x2)\n",
    "\n",
    "2. UPLOAD YOUR AUDIO\n",
    "   - Add Dataset ‚Üí Upload\n",
    "   - Upload your audio file(s)\n",
    "   - Note the path: /kaggle/input/your-dataset-name/\n",
    "\n",
    "3. RUN INSTALLATION (First cell):\n",
    "   !pip install -q openai-whisper transformers accelerate\n",
    "\n",
    "4. COPY THIS CODE to next cell and run\n",
    "\n",
    "5. UPDATE AUDIO PATH:\n",
    "   audio_file = \"/kaggle/input/your-dataset-name/your_audio.mp3\"\n",
    "\n",
    "6. RUN THE CODE!\n",
    "\n",
    "7. DOWNLOAD RESULTS:\n",
    "   - Output section ‚Üí audio_summary.txt ‚Üí Download\n",
    "\n",
    "‚ö° TIPS:\n",
    "- Use GPU for 5-10x faster processing\n",
    "- 'medium' model: best balance for Kaggle\n",
    "- 'base' model: if you hit memory limits\n",
    "- Files save to /kaggle/working/ automatically\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "The ! prefix tells the notebook to run the command as a shell command within the cloud environment.\n",
    "2. Install the System Dependency (PortAudio)\n",
    "Even though Kaggle provides the Python packages, you still need the underlying system driver (libportaudio) on the cloud VM. Kaggle environments support installing these Linux packages using apt-get.\n",
    "Add this to a code cell and run it: and after retart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Code after discussion with the team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cloud code and system audio microphone cannot go hand in hand. hence wokr on a recoded audio mp3 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## step 1: get audio file path \n",
    "# start this code on getting a user input : i.e when record audio icon is clicked at the frontend.\n",
    "# once its clicked, start accessing the mic of the system and fetch the audio.\n",
    "# then convert audio i.e speech to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The PortAudioError: Error querying device -1 message confirms that the libraries are installed correctly within your Kaggle environment, but it cannot find a valid, accessible audio input device.\n",
    "This error is expected because the Kaggle notebook runs in a cloud data center virtual machine that does not have a physical microphone attached to it.\n",
    "The error happens when the sounddevice library tries to find the default microphone on the server and fails, returning a non-existent device ID (-1).\n",
    "\n",
    "Summary of Your Situation\n",
    "You successfully installed the necessary system libraries in Kaggle.\n",
    "You successfully installed the Python libraries (sounddevice, etc.).\n",
    "The limitation is physical hardware: You cannot access your MacBook's mic from the cloud server. \n",
    "What You Should Do Now\n",
    "You must record your audio locally on your MacBook Air and upload the file to Kaggle to analyze it there.\n",
    "Step 1: Record Locally\n",
    "Use the local Python script we established earlier to record audio on your MacBook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Step 2: Speech to text: multilingual input speech to eng text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Step 3: Display the extracted text in the your notes display box. \n",
    "# so give that path. print the text in your notes section.\n",
    "# save this text in a txt file in system or the directory for reference as rough_text.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Step 4: On clicking the AI refined summmary key, i.e again get input from user and define this module,\n",
    "# and run summarisation code on the rough_text.txt file.\n",
    "# save this file as AI-refined-summary.txt for reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Step 5: On user input: fetch code for BRD or PO respectively \n",
    "# code for BRD: if user inputs BRD -Business Required Document format of the summary, \n",
    "# introduce this format to model and ask it to put the summary data in the fields required\n",
    "# Similarly for PO - P order format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key:\n",
    "YOUR_ANTHROPIC_API_KEY_HERE\n",
    "\n",
    "\n",
    "curl https://api.anthropic.com/v1/messages \\\n",
    "        --header \"x-api-key: YOUR_ANTHROPIC_API_KEY_HERE\" \\\n",
    "        --header \"anthropic-version: 2023-06-01\" \\\n",
    "        --header \"content-type: application/json\" \\\n",
    "        --data \\\n",
    "    '{\n",
    "        \"model\": \"claude-sonnet-4-20250514\",\n",
    "        \"max_tokens\": 1024,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Hello, world\"}\n",
    "        ]\n",
    "    }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8832408,
     "sourceId": 13954586,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
